{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5632b274",
   "metadata": {},
   "source": [
    "# Taipy Core\n",
    "\n",
    "Taipy Core is one of the components of Taipy to facilitate pipeline orchestration. There are a lot of reasons for using Taipy Core:\n",
    "\n",
    "- Taipy Core efficiently manages the execution of your functions/pipelines.\n",
    "\n",
    "- Taipy Core manages data sources and monitors KPIs.\n",
    "\n",
    "- Taipy Core provides easy management of multiple pipelines and end-user scenarios, which comes in handy in the context of Machine Learning or Mathematical optimization.\n",
    "\n",
    "To apprehend the Scenario Management aspect of Taipy, you need to understand four essential concepts.\n",
    "\n",
    "\n",
    "## Four fundamental concepts in Taipy Core:\n",
    "- Data Nodes: are the translation of variables in Taipy. Data Nodes don't contain the data but know how to retrieve it. They can refer to any data: any Python object (string, int, list, dict, model, dataframe, etc), a Pickle file, a CSV file, an SQL database, etc. They know how to read and write data. You can even write your own custom Data Node if needed to access a particular data format.\n",
    "\n",
    "- Tasks: are the translation of functions in Taipy.\n",
    "\n",
    "- Pipelines: are a list of tasks executed with intelligent scheduling created automatically by Taipy. They usually represent a sequence of Tasks/functions corresponding to different algorithms like a simple baseline Algorithm or a more sophisticated Machine-Learning pipeline.\n",
    "\n",
    "- Scenarios: End-Users very often require modifying various parameters to reflect different business situations. Taipy Scenarios will provide the framework to \"play\"/\"execute\" pipelines under different conditions/variations (i.e., data/parameters modified by the end user)\n",
    "\n",
    "\n",
    "## What is a configuration?\n",
    "\n",
    "Configuration is the structure or model of what is our scenario. It represents our Direct Acyclic Graph but also how we want our data to be stored or how our code is run. Taipy is able to create multiple instances of this structure with different data thus, we need a way to define it through this configuration step.\n",
    "\n",
    "\n",
    "## Taipy Studio for configuration\n",
    "\n",
    "There are two ways to configure Taipy Core, either by Python code or with Taipy Studio. We strongly recommend using Taipy Studio. \n",
    "\n",
    "Taipy Studio is a VS Code extension that provides a graphical editor to describe pipelines. Everything can be done easily and faster through Taipy Studio. \n",
    "\n",
    "\n",
    "Let's create our first configuration and then create our entities to submit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676c8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0587baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taipy import Config\n",
    "import taipy as tp\n",
    "\n",
    "# Normal function used by Taipy\n",
    "def double(nb):\n",
    "    return nb * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a62317e",
   "metadata": {},
   "source": [
    "Here is the code to configure a simple scenario.\n",
    "\n",
    "Two Data Nodes are being configured 'input' and 'output'. The 'input' Data Node has a _default_data_ put at 21. They will be stored as Pickle files automatically and they are unique to their scenario.\n",
    "\n",
    "The task links the two scenarios through the Python function _double_.\n",
    "\n",
    "The pipeline will contain this one task and the scenario will contain this one pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880241b",
   "metadata": {},
   "source": [
    "______________________ Taipy Studio ______________________\n",
    "- Create new file: 'config.toml'\n",
    "- Open Taipy Studio view\n",
    "- Go to the 'Config files' section of Taipy Studio\n",
    "- Right click on the right configuration\n",
    "- Choose 'Taipy: Show View'\n",
    "- Add your first Data Node by clicking the button on the right above corner of the windows\n",
    "- Create a name for it and change its details in the 'Details' section of Taipy Studio\n",
    "        - name: input\n",
    "        - Details: default_data=21, storage_type:pickle\n",
    "- Do the same for the output\n",
    "        - name: output\n",
    "        - Details: storage_type:pickle\n",
    "- Add a task and choose a function to associate with `<module>.<name>:function`\n",
    "        -name: double\n",
    "        -Details: function=`__main__.double:function`\n",
    "- Link the Data Nodes and the task\n",
    "- Add a pipeline and link it to the task\n",
    "- Add a scenario and link to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaecc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of Data Nodes\n",
    "input_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
    "output_data_node_cfg = Config.configure_data_node(\"output\")\n",
    "\n",
    "# Configuration of tasks\n",
    "task_cfg = Config.configure_task(\"double\",\n",
    "                                 double,\n",
    "                                 input_data_node_cfg,\n",
    "                                 output_data_node_cfg)\n",
    "\n",
    "# Configuration of the pipeline and scenario\n",
    "pipeline_cfg = Config.configure_pipeline(\"my_pipeline\", [task_cfg])\n",
    "scenario_cfg = Config.configure_scenario(\"my_scenario\", [pipeline_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3494889",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchOption",
     "evalue": "No such option: -f",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:514\u001b[0m, in \u001b[0;36mOptionParser._process_opts\u001b[1;34m(self, arg, state)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_long_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_long_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchOption:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# At this point the long option matching failed, and we need\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# to try with short options.  However there is a special rule\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;66;03m# short option code and will instead raise the no option\u001b[39;00m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;66;03m# error.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:398\u001b[0m, in \u001b[0;36mOptionParser._match_long_opt\u001b[1;34m(self, opt, explicit_value, state)\u001b[0m\n\u001b[0;32m    397\u001b[0m     possibilities \u001b[38;5;241m=\u001b[39m get_close_matches(opt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_long_opt)\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchOption(opt, possibilities\u001b[38;5;241m=\u001b[39mpossibilities, ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n\u001b[0;32m    400\u001b[0m option \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_long_opt[opt]\n",
      "\u001b[1;31mNoSuchOption\u001b[0m: No such option: -f",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run of the Core\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tp\u001b[38;5;241m.\u001b[39mCore()\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Creation of the scenario and execution\u001b[39;00m\n\u001b[0;32m      5\u001b[0m scenario \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mcreate_scenario(scenario_cfg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\taipy\\core\\_core.py:44\u001b[0m, in \u001b[0;36mCore.run\u001b[1;34m(self, force_restart)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, force_restart\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Start a Core service. This method is blocking.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     cli_args \u001b[38;5;241m=\u001b[39m \u001b[43mversion_cli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandalone_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cli_args \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# run --help command\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         exit()\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\core.py:1130\u001b[0m, in \u001b[0;36mBaseCommand.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;124;03m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\core.py:1054\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[1;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1054\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_context(prog_name, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[0;32m   1055\u001b[0m             rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(ctx)\n\u001b[0;32m   1056\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standalone_mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\core.py:920\u001b[0m, in \u001b[0;36mBaseCommand.make_context\u001b[1;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[0;32m    915\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_class(\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28mself\u001b[39m, info_name\u001b[38;5;241m=\u001b[39minfo_name, parent\u001b[38;5;241m=\u001b[39mparent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    917\u001b[0m )\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mscope(cleanup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\core.py:1375\u001b[0m, in \u001b[0;36mCommand.parse_args\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mexit()\n\u001b[0;32m   1374\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_parser(ctx)\n\u001b[1;32m-> 1375\u001b[0m opts, args, param_order \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m iter_params_for_processing(param_order, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(ctx)):\n\u001b[0;32m   1378\u001b[0m     value, args \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mhandle_parse_result(ctx, opts, args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:337\u001b[0m, in \u001b[0;36mOptionParser.parse_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    335\u001b[0m state \u001b[38;5;241m=\u001b[39m ParsingState(args)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_args_for_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_args_for_args(state)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError:\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:364\u001b[0m, in \u001b[0;36mOptionParser._process_args_for_options\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt_prefixes \u001b[38;5;129;01mand\u001b[39;00m arglen \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_opts\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_interspersed_args:\n\u001b[0;32m    366\u001b[0m     state\u001b[38;5;241m.\u001b[39mlargs\u001b[38;5;241m.\u001b[39mappend(arg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:523\u001b[0m, in \u001b[0;36mOptionParser._process_opts\u001b[1;34m(self, arg, state)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchOption:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# At this point the long option matching failed, and we need\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# to try with short options.  However there is a special rule\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;66;03m# short option code and will instead raise the no option\u001b[39;00m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;66;03m# error.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt_prefixes:\n\u001b[1;32m--> 523\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_short_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_unknown_options:\n",
      "File \u001b[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\notebook\\lib\\site-packages\\click\\parser.py:436\u001b[0m, in \u001b[0;36mOptionParser._match_short_opt\u001b[1;34m(self, arg, state)\u001b[0m\n\u001b[0;32m    434\u001b[0m         unknown_options\u001b[38;5;241m.\u001b[39mappend(ch)\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchOption(opt, ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option\u001b[38;5;241m.\u001b[39mtakes_value:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# Any characters left in arg?  Pretend they're the\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# next arg, and stop consuming characters of arg.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n",
      "\u001b[1;31mNoSuchOption\u001b[0m: No such option: -f"
     ]
    }
   ],
   "source": [
    "# Run of the Core\n",
    "tp.Core().run()\n",
    "\n",
    "# Creation of the scenario and execution\n",
    "scenario = tp.create_scenario(scenario_cfg)\n",
    "tp.submit(scenario)\n",
    "\n",
    "print(\"Value at the end of task\", scenario.output.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3f345",
   "metadata": {},
   "source": [
    "## Basic functions\n",
    "\n",
    "Let's discuss about the basic functions that comes along with Taipy.\n",
    "\n",
    "-_write_: this is how data can be changed through Taipy. _write_ will change the _last_edit_date_ of the data node which will influence if a task can be skipped or not.\n",
    "\n",
    "-_tp.get_scenarios()_: this function returns a list of all the scenarios\n",
    "\n",
    "-_tp.get()_: this function returns an entity based on the id of the entity\n",
    "\n",
    "-_tp.delete(ID)_: this function deletes the entity and nested elements based on the id of the entity\n",
    "\n",
    "## Utility of having scenarios\n",
    "\n",
    "Taipy lets the user create multiple instances of the same configuration. Datas can differ between instances and can be used to compare different scenarios.\n",
    "\n",
    "Datas can be naturally different depending on the input data nodes or the randomness of functions. Moreover, the user can change them with the _write_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23912c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = tp.create_scenario(scenario_cfg, name=\"Scenario\")\n",
    "tp.submit(scenario)\n",
    "print(\"First submit\", scenario.output.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d7437",
   "metadata": {},
   "source": [
    "By using _write_, data of a Data Node can be changed. The syntax is `<Scenario>.<Pipeline>.<Data Node>.write(value)`. If there is just one pipeline, we can just write `<Scenario>.<Data Node>.write(value)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before write\", scenario.input.read())\n",
    "scenario.input.write(54)\n",
    "print(\"After write\",scenario.input.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b8f81",
   "metadata": {},
   "source": [
    "The submission of the scenario will update the output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.submit(scenario)\n",
    "print(\"Second submit\",scenario.output.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions of Taipy Core \n",
    "# how to access all the scenarios\n",
    "print([s.input.read() for s in tp.get_scenarios()])\n",
    "\n",
    "# how to get a scenario from its id\n",
    "scenario = tp.get(scenario.id)\n",
    "\n",
    "# how to delete a scenario\n",
    "tp.delete(scenario.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb408343",
   "metadata": {},
   "source": [
    "## Different types of Data Nodes:\n",
    "\n",
    "- *Pickle* (default): Taipy can store and read anykind of data that can be serializable.\n",
    "\n",
    "- *CSV*: Taipy can read and store any dataframe as a CSV.\n",
    "\n",
    "- *JSON*: Taipy can read and store any JSONable data as a JSON file.\n",
    "\n",
    "- *SQL*: Taipy can read and store a table or data base.\n",
    "\n",
    "- *Generic*: Taipy provides a generic Data Node that can read and store any data based on the reding and writing function created by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ebf9e1",
   "metadata": {},
   "source": [
    "The execution graph used to explain the different concepts is quite simple.\n",
    "\n",
    "Three Data Nodes:\n",
    "- historical data: initial CSV DataFrame\n",
    "- month_data: DataFrame after the filtering on the month (pd.DataFrame as a Pickle file)\n",
    "- nb_of_values: number of values in this month (int as a Pickle file)\n",
    "\n",
    "Two tasks linking these Data Nodes:\n",
    "- filter: filters on the months of the dataframe\n",
    "- count_values: calculates the number of elements in this month\n",
    "\n",
    "One pipeline in a scenario gathering these two tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5668d",
   "metadata": {},
   "source": [
    "![](config.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecb63b",
   "metadata": {},
   "source": [
    "______________________ Taipy Studio ______________________\n",
    "- Create new file: 'config.toml'\n",
    "- Open Taipy Studio view\n",
    "- Go to the 'Config files' section of Taipy Studio\n",
    "- Right click on the right configuration\n",
    "- Choose 'Taipy: Show View'\n",
    "- Add your first Data Node by clicking the button on the right above corner of the windows\n",
    "- Create a name for it and change its details in the 'Details' section of Taipy Studio\n",
    "        - name: historical_data\n",
    "        - Details: default_path='xxxx/yyyy.csv', storage_type=csv\n",
    "- Do the same for the month_data and nb_of_values\n",
    "        - name: output\n",
    "        - Details: storage_type:pickle\n",
    "- Add a task and choose a function to associate with `<module>.<name>:function`\n",
    "        -name: filter_current\n",
    "        -Details: function=`__main__.filter_current:function`\n",
    "- Do the same for count_values\n",
    "- Link the Data Nodes and the tasks\n",
    "- Add a pipeline and link it to the tasks\n",
    "- Add a scenario and link to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5edc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_current(df):\n",
    "    current_month = dt.datetime.now().month\n",
    "    df['Date'] = pd.to_datetime(df['Date']) \n",
    "    df = df[df['Date'].dt.month == current_month]\n",
    "    return df\n",
    "\n",
    "def count_values(df):\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57040600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a CSV Data Node\n",
    "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
    "                                                     default_path=\"time_series.csv\")\n",
    "month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
    "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_filter_current_cfg = Config.configure_task(id=\"filter_current\",\n",
    "                                                 function=filter_current,\n",
    "                                                 input=historical_data_cfg,\n",
    "                                                 output=month_values_cfg)\n",
    "\n",
    "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
    "                                                 function=count_values,\n",
    "                                                 input=month_values_cfg,\n",
    "                                                 output=nb_of_values_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
    "                                         task_configs=[task_filter_current_cfg,\n",
    "                                                       task_count_values_cfg])\n",
    "\n",
    "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
    "                                         pipeline_configs=[pipeline_cfg])\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_current_cfg,\n",
    "#                                                                  task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Core().run()\n",
    "\n",
    "scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
    "scenario_1.submit()\n",
    "\n",
    "scenario_2 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
    "scenario_2.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4097e",
   "metadata": {},
   "source": [
    "## Cycles :\n",
    "\n",
    "So far, we have talked about how having different scenarios helps us to oversee our assumptions about the future. For example, in business, it is critical to weigh different options to come up with an optimal solution. However, this decision-making process isn’t just a one-time task but rather a recurrent operation that happens over a time period. This is why we want to introduce Cycles.\n",
    "\n",
    "A cycle can be thought of as a place to store different and recurrent scenarios within a time frame. In Taipy Core, each Cycle will have a unique primary scenario representing the reference scenario for a time period.\n",
    "\n",
    "\n",
    "Typically, in a Machine Learning problem, many scenarios are created daily to predict the next day, for example. Among all those scenarios, there is only one primary scenario. In the step's example, scenarios are attached to a MONTHLY cycle. Using Cycles is useful because some specific Taipy's functions exist to navigate through these Cycles. Taipy can get all the scenarios created in a month by providing the Cycle. You can also get every primary scenario ever made to see their progress over time quickly.\n",
    "\n",
    "Moreover, nothing is more straightforward than creating a Cycle. The frequency parameter in a scenario configuration will produce the desired type of Cycle. In the code below, the scenario has a monthly cycle. When it is created, it will be attached to the correct period (month).\n",
    "\n",
    "As you can see, a Cycle can be made very easily once you have the desired frequency. In this snippet of code, since we have specified frequency=Frequency.MONTHLY, the corresponding scenario will be automatically attached to the correct period (month) once it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e09daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[2022-12-15 10:12:40,104][Taipy][INFO] job JOB_filter_by_month_9d986a1d-63fd-4eb1-8f75-2544eb34424b is completed.\n",
    "#[2022-12-15 10:12:40,155][Taipy][INFO] job JOB_count_values_3b515b56-21b6-40f6-94dd-32e4a3da35dd is completed.\n",
    "#[2022-12-15 10:12:40,345][Taipy][INFO] job JOB_filter_by_month_d540c831-9d73-4555-8d69-a2a546a77467 is completed.\n",
    "#[2022-12-15 10:12:40,400][Taipy][INFO] job JOB_count_values_ec296987-6178-43cd-8f28-1a990893733a is completed.\n",
    "#[2022-12-15 10:12:40,590][Taipy][INFO] job JOB_filter_by_month_42d4f0db-d911-40f5-b820-02e750f77ba5 is completed.\n",
    "#[2022-12-15 10:12:40,643][Taipy][INFO] job JOB_count_values_53caf39c-0060-46c1-8d48-3dc6b5e74d02 is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080d69d",
   "metadata": {},
   "source": [
    "Also, as you can see every scenario has been submitted and executed entirely. However, the result for these tasks are all the same. Caching will help to skip certain redundant task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fde13",
   "metadata": {},
   "source": [
    "______________________ Taipy Studio ______________________\n",
    "- Create new file: 'config.toml'\n",
    "- Open Taipy Studio view\n",
    "- Go to the 'Config files' section of Taipy Studio\n",
    "- Right click on the right configuration\n",
    "- Choose 'Taipy: Show View'\n",
    "- Add your first Data Node by clicking the button on the right above corner of the windows\n",
    "- Create a name for it and change its details in the 'Details' section of Taipy Studio\n",
    "        - name: historical_data\n",
    "        - Details: default_path='xxxx/yyyy.csv', storage_type=csv\n",
    "- Do the same for the month_data and nb_of_values\n",
    "        - name: output\n",
    "        - Details: storage_type:pickle\n",
    "- Add a task and choose a function to associate with `<module>.<name>:function`\n",
    "        -name: filter_current\n",
    "        -Details: function=`__main__.filter_current:function`\n",
    "- Do the same for count_values\n",
    "- Link the Data Nodes and the tasks\n",
    "- Add a pipeline and link it to the tasks\n",
    "- Add a scenario and link to the pipeline\n",
    "- Add the frequency property and put \"WEEKLY:FREQUENCY\" (DAYLY, WEEKLY, MONTHLY, YEARLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65713157",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taipy.core.config import Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80858ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_month(df, month):\n",
    "    df['Date'] = pd.to_datetime(df['Date']) \n",
    "    df = df[df['Date'].dt.month == month]\n",
    "    return df\n",
    "\n",
    "def count_values(df):\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
    "                                                     default_path=\"time_series.csv\")\n",
    "month_cfg =  Config.configure_data_node(id=\"month\")\n",
    "month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
    "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n",
    "\n",
    "\n",
    "task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
    "                                                 function=filter_by_month,\n",
    "                                                 input=[historical_data_cfg, month_cfg],\n",
    "                                                 output=month_values_cfg)\n",
    "\n",
    "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
    "                                                 function=count_values,\n",
    "                                                 input=month_values_cfg,\n",
    "                                                 output=nb_of_values_cfg)\n",
    "\n",
    "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
    "                                         task_configs=[task_filter_by_month_cfg,\n",
    "                                                       task_count_values_cfg])\n",
    "\n",
    "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
    "                                         pipeline_configs=[pipeline_cfg],\n",
    "                                         frequency=Frequency.MONTHLY)\n",
    "\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_by_month_cfg,\n",
    "#                                                    task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28decd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Core().run()\n",
    "\n",
    "scenario_1 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,10,7),\n",
    "                                name=\"Scenario 2022/10/7\")\n",
    "scenario_2 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,10,5),\n",
    "                                name=\"Scenario 2022/10/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abec152",
   "metadata": {},
   "source": [
    "Scenario 1 and 2 belongs to the same cycle but they don't share the same data node. Each one have a Data Node by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.month.write(10)\n",
    "scenario_2.month.write(10)\n",
    "\n",
    "\n",
    "print(\"Month Data Node of Scenario 1\", scenario_1.month.read())\n",
    "print(\"Month Data Node of Scenario 2\", scenario_2.month.read())\n",
    "\n",
    "scenario_1.submit()\n",
    "scenario_2.submit()\n",
    "\n",
    "scenario_3 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2021,9,1),\n",
    "                                name=\"Scenario 2022/9/1\")\n",
    "scenario_3.month.write(9)\n",
    "scenario_3.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96962e",
   "metadata": {},
   "source": [
    "## Scoping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04fbc3",
   "metadata": {},
   "source": [
    "Scoping determines how Data Nodes are shared between cycles, scenarios, and pipelines. Indeed, multiple scenarios can have their own Data Nodes or share the same one. For example, the initial/historical dataset is usually shared by all the scenarios/pipelines/cycles. It has a Global Scope and will be unique in the entire application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7161d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taipy.core.config import Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0655a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_month(df, month):\n",
    "    df['Date'] = pd.to_datetime(df['Date']) \n",
    "    df = df[df['Date'].dt.month == month]\n",
    "    return df\n",
    "\n",
    "def count_values(df):\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeab6f9",
   "metadata": {},
   "source": [
    "- **Pipeline** scope: two pipelines can reference different Data Nodes even if their names are the same. For example, the _prediction_ Data Node of an ARIMA model (ARIMA pipeline) and the _prediction_ Data Node of a RandomForest model (RandomForest pipeline). \n",
    "\n",
    "- **Scenario** scope: pipelines share the same Data Node within a scenario. \n",
    "\n",
    "- **Cycle** scope: scenarios from the same cycle share the same Data Node\n",
    "\n",
    "- **Global** scope: unique Data Node for all the scenarios/pipelines/cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76695ec2",
   "metadata": {},
   "source": [
    "______________________ Taipy Studio ______________________\n",
    "- Create new file: 'config.toml'\n",
    "- Open Taipy Studio view\n",
    "- Go to the 'Config files' section of Taipy Studio\n",
    "- Right click on the right configuration\n",
    "- Choose 'Taipy: Show View'\n",
    "- Add your first Data Node by clicking the button on the right above corner of the windows\n",
    "- Create a name for it and change its details in the 'Details' section of Taipy Studio\n",
    "        - name: historical_data\n",
    "        - Details: default_path=xxxx/yyyy.csv, storage_type=csv\n",
    "- Do the same for the month_data and nb_of_values\n",
    "        - name: output\n",
    "        - Details: storage_type:pickle\n",
    "- Add a task and choose a function to associate with `<module>.<name>:function`\n",
    "        -name: filter_current\n",
    "        -Details: function=`__main__.filter_current:function`\n",
    "- Do the same for count_values\n",
    "- Link the Data Nodes and the tasks\n",
    "- Add a pipeline and link it to the tasks\n",
    "- Add a scenario and link to the pipeline\n",
    "- Add the frequency property and put \"WEEKLY:FREQUENCY\" (DAILY, WEEKLY, MONTHLY, YEARLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
    "                                                 default_path=\"time_series.csv\",\n",
    "                                                 scope=Scope.GLOBAL)\n",
    "month_cfg =  Config.configure_data_node(id=\"month\", scope=Scope.CYCLE)\n",
    "\n",
    "month_values_cfg = Config.configure_data_node(id=\"month_data\",\n",
    "                                               scope=Scope.CYCLE)\n",
    "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n",
    "\n",
    "\n",
    "task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
    "                                                 function=filter_by_month,\n",
    "                                                 input=[historical_data_cfg,month_cfg],\n",
    "                                                 output=month_values_cfg)\n",
    "\n",
    "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
    "                                                 function=count_values,\n",
    "                                                 input=month_values_cfg,\n",
    "                                                 output=nb_of_values_cfg)\n",
    "\n",
    "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
    "                                         task_configs=[task_filter_by_month_cfg,\n",
    "                                                       task_count_values_cfg])\n",
    "\n",
    "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
    "                                         pipeline_configs=[pipeline_cfg],\n",
    "                                         frequency=Frequency.MONTHLY)\n",
    "\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_by_month_cfg,\n",
    "#                                                                  task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54956b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Core().run()\n",
    "\n",
    "scenario_1 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,10,7),\n",
    "                                name=\"Scenario 2022/10/7\")\n",
    "scenario_2 = tp.create_scenario(scenario_cfg,\n",
    "                               creation_date=dt.datetime(2022,10,5),\n",
    "                               name=\"Scenario 2022/10/5\")\n",
    "scenario_3 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2021,9,1),\n",
    "                                name=\"Scenario 2021/9/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd643b1",
   "metadata": {},
   "source": [
    "Scenario 1 and 2 belongs to the same cycle so I can define the month just once for scenario 1 and 2 because month has a Cycle scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249d7a6",
   "metadata": {},
   "source": [
    "![]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1.month.write(10)\n",
    "print(\"Scenario 1: month\", scenario_1.month.read())\n",
    "print(\"Scenario 2: month\", scenario_2.month.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ca569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScenario 1: submit\")\n",
    "scenario_1.submit()\n",
    "print(\"Value\", scenario_1.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07520802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScenario 2: first submit\")\n",
    "scenario_2.submit()\n",
    "print(\"Value\", scenario_2.nb_of_values.read())\n",
    "print(\"Scenario 2: second submit\")\n",
    "scenario_2.submit()\n",
    "print(\"Value\", scenario_2.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7db125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScenario 3: submit\")\n",
    "scenario_3.month.write(9)\n",
    "scenario_3.submit()\n",
    "print(\"Value\", scenario_3.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scenario 3: change in historical data\")\n",
    "scenario_3.historical_data.write(pd.read_csv('time_series_2.csv'))\n",
    "scenario_3.submit()\n",
    "print(\"Value\", scenario_3.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db78c1d",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832d9ca",
   "metadata": {},
   "source": [
    "Caching is an important feature of Taipy. Tasks can be skipped depending if input data nodes of tasks have changed or not. If none of the input data nodes have been changed after a first submission, tasks will be skipped saving time and ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477242d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_month(df, month):\n",
    "    df['Date'] = pd.to_datetime(df['Date']) \n",
    "    df = df[df['Date'].dt.month == month]\n",
    "    return df\n",
    "\n",
    "def count_values(df):\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07748038",
   "metadata": {},
   "source": [
    "______________________ Taipy Studio ______________________\n",
    "- Create new file: 'config.toml'\n",
    "- Open Taipy Studio view\n",
    "- Go to the 'Config files' section of Taipy Studio\n",
    "- Right click on the right configuration\n",
    "- Choose 'Taipy: Show View'\n",
    "- Add your first Data Node by clicking the button on the right above corner of the windows\n",
    "- Create a name for it and change its details in the 'Details' section of Taipy Studio\n",
    "        - name: historical_data\n",
    "        - Details: default_path=xxxx/yyyy.csv, storage_type=csv\n",
    "- Do the same for the month_data and nb_of_values\n",
    "        - name: output\n",
    "        - Details: storage_type:pickle, cacheable=True\n",
    "- Add a task and choose a function to associate with `<module>.<name>:function`\n",
    "        -name: filter_current\n",
    "        -Details: function=`__main__.filter_current:function`\n",
    "- Do the same for count_values\n",
    "- Link the Data Nodes and the tasks\n",
    "- Add a pipeline and link it to the tasks\n",
    "- Add a scenario and link to the pipeline\n",
    "- Add the frequency property and put \"WEEKLY:FREQUENCY\" (DAILY, WEEKLY, MONTHLY, YEARLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df912c",
   "metadata": {},
   "source": [
    "The configuration is the same. 'cacheabable' are added to the output Data Nodes that we want to be cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a52f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
    "                                                 default_path=\"time_series.csv\",\n",
    "                                                 scope=Scope.GLOBAL)\n",
    "month_cfg =  Config.configure_data_node(id=\"month\", scope=Scope.CYCLE)\n",
    "month_values_cfg =  Config.configure_data_node(id=\"month_data\",\n",
    "                                               scope=Scope.CYCLE,\n",
    "                                               cacheable=True)\n",
    "\n",
    "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\",\n",
    "                                              cacheable=True)\n",
    "\n",
    "\n",
    "task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
    "                                                 function=filter_by_month,\n",
    "                                                 input=[historical_data_cfg, month_cfg],\n",
    "                                                 output=month_values_cfg)\n",
    "\n",
    "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
    "                                                 function=count_values,\n",
    "                                                 input=month_values_cfg,\n",
    "                                                 output=nb_of_values_cfg)\n",
    "\n",
    "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
    "                                         task_configs=[task_filter_by_month_cfg,\n",
    "                                                       task_count_values_cfg])\n",
    "\n",
    "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
    "                                         pipeline_configs=[pipeline_cfg],\n",
    "                                         frequency=Frequency.MONTHLY)\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_by_month_cfg,\n",
    "#                                                    task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98199352",
   "metadata": {},
   "source": [
    "Creation of three different scenarios with different creation dates and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b31563",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Core().run()\n",
    "\n",
    "scenario_1 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,10,7),\n",
    "                                name=\"Scenario 2022/10/7\")\n",
    "scenario_2 = tp.create_scenario(scenario_cfg,\n",
    "                               creation_date=dt.datetime(2022,10,5),\n",
    "                               name=\"Scenario 2022/10/5\")\n",
    "scenario_3 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2021,9,1),\n",
    "                                name=\"Scenario 2022/9/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 1 and 2 belongs to the same cycle so \n",
    "# defining the month for scenario 1 defines the month for the scenarios in the cycle\n",
    "scenario_1.month.write(10)\n",
    "print(\"Scenario 1: month\", scenario_1.month.read())\n",
    "print(\"Scenario 2: month\", scenario_2.month.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e0a60",
   "metadata": {},
   "source": [
    " No task has already been submitted so everything will be submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e159015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scenario 1: submit\")\n",
    "scenario_1.submit()\n",
    "print(\"Value\", scenario_1.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b454d",
   "metadata": {},
   "source": [
    "When the second scenario is being executed, the first task will be skipped. Indeed, the two scenarios shares the same data nodes for this task and no input data nodes have been changed. node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first task has already been executed by scenario 1 because scenario 2 shares the same data node for this task\n",
    "print(\"Scenario 2: first submit\")\n",
    "scenario_2.submit()\n",
    "print(\"Value\", scenario_2.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405d699",
   "metadata": {},
   "source": [
    "Resubmitting the same scenario without any change will just skip every task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every task has already been executed so everything will be skipped\n",
    "print(\"Scenario 2: second submit\")\n",
    "scenario_2.submit()\n",
    "print(\"Value\", scenario_2.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec6ece",
   "metadata": {},
   "source": [
    "This scenario is not in the same cycle. We change the month to 9 and every task will be completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 3 has no connection to the other scenarios so everything will be executed\n",
    "print(\"Scenario 3: submit\")\n",
    "scenario_3.month.write(9)\n",
    "scenario_3.submit()\n",
    "print(\"Value\", scenario_3.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9f288",
   "metadata": {},
   "source": [
    "Here, we change the input data node of the pipeline so Taipy will re run the correct tasks to make sure that everything is up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing an input data node will make the task be reexecuted\n",
    "print(\"Scenario 3: change in historical data\")\n",
    "scenario_3.historical_data.write(pd.read_csv('time_series_2.csv'))\n",
    "scenario_3.submit()\n",
    "print(\"Value\", scenario_3.nb_of_values.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d34e32",
   "metadata": {},
   "source": [
    "## Execution modes\n",
    "\n",
    "Taipy has different ways to execute the code. There is two different job execution modes:\n",
    "- standalone: asynchronous. Jobs can be runned in parallel depending on the graph of execution if max_nb_of_workers > 1\n",
    "- development mode: synchronous\n",
    "\n",
    "Options of submit:\n",
    "- wait: if wait is True, the submit is synchronous and will wait for the end of all the jobs (if timeout is not defined)\n",
    "- timeout: if wait is True, Taipy will wait for the end of the submit until a certain amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47223948",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a120fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Taipy Core Data nodes - CSV, pickle\n",
    "from taipy.core.config import Config, Scope, Frequency\n",
    "import taipy as tp\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08105ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_month(df, month):\n",
    "    df['Date'] = pd.to_datetime(df['Date']) \n",
    "    df = df[df['Date'].dt.month == month]\n",
    "    return df\n",
    "\n",
    "def count_values(df):\n",
    "    print(\"Wait 10 seconds\")\n",
    "    time.sleep(10)\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.configure_job_executions(mode=\"standalone\", max_nb_of_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
    "                                                 default_path=\"time_series.csv\",\n",
    "                                                 scope=Scope.GLOBAL)\n",
    "\n",
    "month_cfg = Config.configure_data_node(id=\"month\",\n",
    "                                       scope=Scope.CYCLE)\n",
    "\n",
    "month_values_cfg =  Config.configure_data_node(id=\"month_data\",\n",
    "                                               scope=Scope.CYCLE,\n",
    "                                               cacheable=True)\n",
    "\n",
    "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\",\n",
    "                                              cacheable=True)\n",
    "\n",
    "\n",
    "task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
    "                                                 function=filter_by_month,\n",
    "                                                 input=[historical_data_cfg, month_cfg],\n",
    "                                                 output=month_values_cfg)\n",
    "\n",
    "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
    "                                                 function=count_values,\n",
    "                                                 input=month_values_cfg,\n",
    "                                                 output=nb_of_values_cfg)\n",
    "\n",
    "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
    "                                         task_configs=[task_filter_by_month_cfg,\n",
    "                                                       task_count_values_cfg])\n",
    "\n",
    "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
    "                                         pipeline_configs=[pipeline_cfg],\n",
    "                                         frequency=Frequency.MONTHLY)\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_by_month_cfg,\n",
    "#                                                    task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538da846",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    tp.Core().run()\n",
    "    scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
    "    scenario_1.month.write(10)\n",
    "    scenario_1.submit()\n",
    "    scenario_1.submit()\n",
    "\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253faa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    tp.Core().run()\n",
    "    scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
    "    scenario_1.month.write(10)\n",
    "    scenario_1.submit(wait=True)\n",
    "    scenario_1.submit(wait=True, timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56e351d",
   "metadata": {},
   "source": [
    "## Callback on scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5f71",
   "metadata": {},
   "source": [
    "To have an action after the change of status of a job, we can subscribe a function to a scenario. This function will be called each time a job has its status changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f90b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_scenario_state(scenario, job):\n",
    "    \"\"\"All the scenarios are subscribed to the callback_scenario_state function. It means whenever a job is done, it is called.\n",
    "    Depending on the job and the status, it will update the message stored in a json that is then displayed on the GUI.\n",
    "\n",
    "    Args:\n",
    "        scenario (Scenario): the scenario of the job changed\n",
    "        job (_type_): the job that has its status changed\n",
    "    \"\"\"\n",
    "    print(scenario.name)\n",
    "    if job.status.value == 7:\n",
    "        for data_node in job.task.output.values():\n",
    "            print(data_node.read())\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    tp.Core().run()\n",
    "    scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
    "    scenario_1.subscribe(callback_scenario_state)\n",
    "\n",
    "    scenario_1.submit(wait=True)\n",
    "    scenario_1.submit(wait=True, timeout=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7cf109",
   "metadata": {},
   "source": [
    "## Comparison of funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce00b74",
   "metadata": {},
   "source": [
    "Taipy provides a way to compare scenarios by providing a function directly into the configuration of the scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaa6dc",
   "metadata": {},
   "source": [
    "_data_node_results_ is a list of data nodes from all scenarios passed in the comparator. We iterate through it to compare scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_function(*data_node_results):\n",
    "    compare_result= {}\n",
    "    current_res_i = 0\n",
    "    for current_res in data_node_results:\n",
    "        compare_result[current_res_i]={}\n",
    "        next_res_i = 0\n",
    "        for next_res in data_node_results:\n",
    "            print(f\"comparing result {current_res_i} with result {next_res_i}\")\n",
    "            compare_result[current_res_i][next_res_i] = next_res - current_res\n",
    "            next_res_i += 1\n",
    "        current_res_i += 1\n",
    "    return compare_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c913c1",
   "metadata": {},
   "source": [
    "The Data Node that will be compared here is the 'month' Data Node. It is indicated in the comparators parameter of the _configure_scenario_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_cfg = Config.configure_scenario(\"multiply_scenario\",\n",
    "                                         [pipeline_cfg],\n",
    "                                         comparators={month_cfg.id: compare_function},\n",
    "                                         frequency=Frequency.MONTHLY)\n",
    "\n",
    "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
    "#                                                    task_configs=[task_filter_by_month_cfg,\n",
    "#                                                                  task_count_values_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd62c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Core().run()\n",
    "\n",
    "scenario_1 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,10,7),\n",
    "                                name=\"Scenario 2022/10/7\")\n",
    "scenario_2 = tp.create_scenario(scenario_cfg,\n",
    "                                creation_date=dt.datetime(2022,8,5),\n",
    "                                name=\"Scenario 2022/8/5\")\n",
    "\n",
    "scenario_1.month.write(10)\n",
    "scenario_2.month.write(8)\n",
    "print(\"Scenario 1: month\", scenario_1.month.read())\n",
    "print(\"Scenario 2: month\", scenario_2.month.read())\n",
    "\n",
    "print(\"\\nScenario 1: submit\")\n",
    "scenario_1.submit()\n",
    "print(\"Value\", scenario_1.nb_of_values.read())\n",
    "\n",
    "print(\"\\nScenario 2: first submit\")\n",
    "scenario_2.submit()\n",
    "print(\"Value\", scenario_2.nb_of_values.read())\n",
    "\n",
    "\n",
    "print(tp.compare_scenarios(scenario_1, scenario_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f170174",
   "metadata": {},
   "source": [
    "## Taipy Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c540edf",
   "metadata": {},
   "source": [
    "Taipy Rest allows the user to navigate through the entities of the application but also create and submit scenarios. Try the following commands:\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e42d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.Rest().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e306d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
