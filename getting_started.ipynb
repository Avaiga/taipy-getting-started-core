{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Taipy Core on Notebooks\n",
        "\n",
        "!!! important \"Supported Python versions\"\n",
        "\n",
        "    Taipy requires **Python 3.8** or newer.\n",
        "\n",
        "Welcome to the **Getting Started** guide for Taipy Core. This tour shows you how to use Taipy Core to orchestrate pipelines. Taipy Core implements a modern backend for any data-driven application based on your business case.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_00/imd_end_interface.png width=700>\n",
        "</div>\n",
        "\n",
        "# Taipy Core\n",
        "\n",
        "Taipy Core is one of the components of Taipy to facilitate pipeline orchestration. There are a lot of reasons for using Taipy Core:\n",
        "\n",
        "- Taipy Core efficiently manages the execution of your functions/pipelines.\n",
        "\n",
        "- Taipy Core manages data sources and monitors KPIs.\n",
        "\n",
        "- Taipy Core provides easy management of multiple pipelines and end-user scenarios, which comes in handy in the context of Machine Learning or Mathematical optimization.\n",
        "\n",
        "To apprehend the Scenario Management aspect of Taipy, you need to understand four essential concepts.\n",
        "\n",
        "Each step of the **\"Getting Started\"** will focus on basic concepts of *Taipy*. Note that every step is dependent on \n",
        "the code of the previous one. After completing the last step, you will have the skills to develop your own Taipy \n",
        "application. \n",
        "\n",
        "## Before we begin\n",
        "\n",
        "Only Taipy has to be installed. **Taipy** package requires Python 3.8 or newer;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# !pip install taipy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Notebooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration and execution\n",
        "## Four fundamental concepts in Taipy Core:\n",
        "- Data Nodes: are the translation of variables in Taipy. Data Nodes don't contain the data but know how to retrieve it. They can refer to any data: any Python object (string, int, list, dict, model, dataframe, etc), a Pickle file, a CSV file, an SQL database, etc. They know how to read and write data. You can even write your own custom Data Node if needed to access a particular data format.\n",
        "\n",
        "- Tasks: are the translation of functions in Taipy.\n",
        "\n",
        "- Pipelines: are a list of tasks executed with intelligent scheduling created automatically by Taipy. They usually represent a sequence of Tasks/functions corresponding to different algorithms like a simple baseline Algorithm or a more sophisticated Machine-Learning pipeline.\n",
        "\n",
        "- Scenarios: End-Users very often require modifying various parameters to reflect different business situations. Taipy Scenarios will provide the framework to \"play\"/\"execute\" pipelines under different conditions/variations (i.e., data/parameters modified by the end user)\n",
        "\n",
        "\n",
        "## What is a configuration?\n",
        "\n",
        "Configuration is the structure or model of what is our scenario. It represents our Direct Acyclic Graph but also how we want our data to be stored or how our code is run. Taipy is able to create multiple instances of this structure with different data thus, we need a way to define it through this configuration step.\n",
        "\n",
        "\n",
        "Let's create our first configuration and then create our entities to submit through Taipy Studio or direct Python Code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 1,
      "source": [
        "from taipy import Config\n",
        "import taipy as tp\n",
        "\n",
        "# Normal function used by Taipy\n",
        "def double(nb):\n",
        "    return nb * 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_01/config_01.svg width=700>\n",
        "</div>\n",
        "\n",
        "- Two Data Nodes are being configured ('input' and 'output'). The 'input' Data Node has a _default_data_ put at 21. They will be stored as Pickle files by default, and are unique to their scenario.\n",
        "\n",
        "- The task links the two Data Nodes through the Python function _double_.\n",
        "\n",
        "- The pipeline will contain this one task, and the scenario will contain this one pipeline.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_01/config_01.gif width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "Here is the code to configure a simple scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 2,
      "source": [
        "# Configuration of Data Nodes\n",
        "input_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
        "output_data_node_cfg = Config.configure_data_node(\"output\")\n",
        "\n",
        "# Configuration of tasks\n",
        "task_cfg = Config.configure_task(\"double\",\n",
        "                                 double,\n",
        "                                 input_data_node_cfg,\n",
        "                                 output_data_node_cfg)\n",
        "\n",
        "# Configuration of the pipeline and scenario\n",
        "pipeline_cfg = Config.configure_pipeline(\"my_pipeline\", [task_cfg])\n",
        "scenario_cfg = Config.configure_scenario(\"my_scenario\", [pipeline_cfg])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 3,
      "source": [
        "# Run of the Core\n",
        "tp.Core().run()\n",
        "\n",
        "# Creation of the scenario and execution\n",
        "scenario = tp.create_scenario(scenario_cfg)\n",
        "tp.submit(scenario)\n",
        "\n",
        "print(\"Value at the end of task\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "```\n",
        "[2022-12-22 16:20:02,740][Taipy][INFO] job JOB_double_699613f8-7ff4-471b-b36c-d59fb6688905 is completed.\n",
        "Value at the end of task 42\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic functions\n",
        "\n",
        "Let's discuss the basic functions that come along with Taipy.\n",
        "\n",
        "- `<Data Node>.write(<new value>)`: this is how data can be changed through Taipy. _write_ will change the _last_edit_date_ of the data node, which will influence if a task can be skipped or not.\n",
        "\n",
        "-`tp.get_scenarios()`: this function returns a list of all the scenarios\n",
        "\n",
        "-`tp.get(<Taipy object ID>)`: this function returns an entity based on the id of the entity\n",
        "\n",
        "-`tp.delete(<Taipy object ID>)`: this function deletes the entity and nested elements based on the id of the entity\n",
        "\n",
        "## Utility of having scenarios\n",
        "\n",
        "Taipy lets the user create multiple instances of the same configuration. Data can differ between instances and can be used to compare different scenarios.\n",
        "\n",
        "Data can naturally differ depending on the input Data Nodes or the randomness of functions. Moreover, the user can change them with the _write_ function.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_02/config_02.svg width=700>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 4,
      "source": [
        "scenario = tp.create_scenario(scenario_cfg, name=\"Scenario\")\n",
        "tp.submit(scenario)\n",
        "print(\"First submit\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "```\n",
        "[2022-12-22 16:20:02,874][Taipy][INFO] job JOB_double_a5ecfa4d-1963-4776-8f68-0859d22970b9 is completed.\n",
        "First submit 42\n",
        "```\n",
        "\n",
        "## _write_ function\n",
        "\n",
        "Using _write_, data of a Data Node can be changed. The syntax is `<Scenario>.<Pipeline>.<Data Node>.write(value)`. If there is just one pipeline, we can just write `<Scenario>.<Data Node>.write(value)`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 5,
      "source": [
        "print(\"Before write\", scenario.input.read())\n",
        "scenario.input.write(54)\n",
        "print(\"After write\",scenario.input.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "Before write 21\n",
        "After write 54\n",
        "```\n",
        "\n",
        "The submission of the scenario will update the output values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 6,
      "source": [
        "tp.submit(scenario)\n",
        "print(\"Second submit\",scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "```\n",
        "[2022-12-22 16:20:03,011][Taipy][INFO] job JOB_double_7eee213f-062c-4d67-b0f8-4b54c04e45e7 is completed.\n",
        "Second submit 108\n",
        "```\n",
        "\n",
        "## Other useful functions\n",
        "\n",
        "- how to access all the scenarios\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 7,
      "source": [
        "print([s.input.read() for s in tp.get_scenarios()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "[21, 54]\n",
        "```\n",
        "\n",
        "- get an entity from its id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 8,
      "source": [
        "scenario = tp.get(scenario.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- delete an entity though its id. Example: how to delete a scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 9,
      "source": [
        "tp.delete(scenario.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Different types of Data Nodes:\n",
        "\n",
        "- *[Pickle](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#pickle)* (default): Taipy can store and read anykind of data that can be serializable.\n",
        "\n",
        "- *[CSV](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#csv)*: Taipy can read and store any dataframe as a CSV.\n",
        "\n",
        "- *[JSON](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#json)*: Taipy can read and store any JSONable data as a JSON file.\n",
        "\n",
        "- *[SQL](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#sql)*: Taipy can read and store a table or data base.\n",
        "\n",
        "- *[Generic](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#generic)*: Taipy provides a generic Data Node that can read and store any data based on the reding and writing function created by the user.\n",
        "\n",
        "The execution graph used to explain the different concepts is quite simple.\n",
        "\n",
        "1) Three Data Nodes:\n",
        "- _historical data_: initial CSV DataFrame\n",
        "- _month_data_: DataFrame after the filtering on the month (a _Pandas.DataFrame_ as a Pickle file)\n",
        "- _nb_of_values_: number of values in this month (int as a Pickle file)\n",
        "\n",
        "2) Two tasks linking these Data Nodes:\n",
        "- _filter_: filters on the months of the dataframe\n",
        "- _count_values_: calculates the number of elements in this month\n",
        "\n",
        "3) One pipeline in a scenario gathering these two tasks.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_03/config_03.svg width=700>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 10,
      "source": [
        "import datetime as dt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 11,
      "source": [
        "def filter_current(df):\n",
        "    current_month = dt.datetime.now().month\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == current_month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://github.com/Avaiga/taipy-getting-started-core/blob/develop/step_03/config_03.gif width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 12,
      "source": [
        "# here is a CSV Data Node\n",
        "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                     default_path=\"time_series.csv\")\n",
        "month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
        "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 13,
      "source": [
        "task_filter_current_cfg = Config.configure_task(id=\"filter_current\",\n",
        "                                                 function=filter_current,\n",
        "                                                 input=historical_data_cfg,\n",
        "                                                 output=month_values_cfg)\n",
        "\n",
        "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                 function=count_values,\n",
        "                                                 input=month_values_cfg,\n",
        "                                                 output=nb_of_values_cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 14,
      "source": [
        "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                         task_configs=[task_filter_current_cfg,\n",
        "                                                       task_count_values_cfg])\n",
        "\n",
        "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                         pipeline_configs=[pipeline_cfg])\n",
        "\n",
        "#scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "#                                                    task_configs=[task_filter_current_cfg,\n",
        "#                                                                  task_count_values_cfg])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 15,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "scenario_1.submit()\n",
        "\n",
        "scenario_2 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "scenario_2.submit()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}