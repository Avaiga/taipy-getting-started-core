{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Taipy Core on Notebooks\n",
        "\n",
        "!!! important \"Supported Python versions\"\n",
        "\n",
        "    Taipy requires **Python 3.8** or newer.\n",
        "\n",
        "Welcome to the **Getting Started** guide for Taipy Core. This tour shows you how to use Taipy Core to orchestrate pipelines. Taipy Core implements a modern backend for any data-driven application based on your business case.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://docs.taipy.io/en/latest/getting_started/step_00/imd_end_interface.png width=700>\n",
        "</div>\n",
        "\n",
        "# Taipy Core\n",
        "\n",
        "Taipy Core is one of the components of Taipy to facilitate pipeline orchestration. There are a lot of reasons for using Taipy Core:\n",
        "\n",
        "- Taipy Core efficiently manages the execution of your functions/pipelines.\n",
        "\n",
        "- Taipy Core manages data sources and monitors KPIs.\n",
        "\n",
        "- Taipy Core provides easy management of multiple pipelines and end-user scenarios, which comes in handy in the context of Machine Learning or Mathematical optimization.\n",
        "\n",
        "To apprehend the Scenario Management aspect of Taipy, you need to understand four essential concepts.\n",
        "\n",
        "Each step of the **\"Getting Started\"** will focus on basic concepts of *Taipy*. Note that every step is dependent on \n",
        "the code of the previous one. After completing the last step, you will have the skills to develop your own Taipy \n",
        "application. \n",
        "\n",
        "## Before we begin\n",
        "\n",
        "Only Taipy has to be installed. **Taipy** package requires Python 3.8 or newer;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# !pip install taipy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Notebooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration and execution\n",
        "## Four fundamental concepts in Taipy Core:\n",
        "- Data Nodes: are the translation of variables in Taipy. Data Nodes don't contain the data but know how to retrieve it. They can refer to any data: any Python object (string, int, list, dict, model, dataframe, etc), a Pickle file, a CSV file, an SQL database, etc. They know how to read and write data. You can even write your own custom Data Node if needed to access a particular data format.\n",
        "\n",
        "- Tasks: are the translation of functions in Taipy.\n",
        "\n",
        "- Pipelines: are a list of tasks executed with intelligent scheduling created automatically by Taipy. They usually represent a sequence of Tasks/functions corresponding to different algorithms like a simple baseline Algorithm or a more sophisticated Machine-Learning pipeline.\n",
        "\n",
        "- Scenarios: End-Users very often require modifying various parameters to reflect different business situations. Taipy Scenarios will provide the framework to \"play\"/\"execute\" pipelines under different conditions/variations (i.e., data/parameters modified by the end user)\n",
        "\n",
        "\n",
        "## What is a configuration?\n",
        "\n",
        "Configuration is the structure or model of what is our scenario. It represents our Direct Acyclic Graph but also how we want our data to be stored or how our code is run. Taipy is able to create multiple instances of this structure with different data thus, we need a way to define it through this configuration step.\n",
        "\n",
        "\n",
        "Let's create our first configuration and then create our entities to submit either through Taipy Studio or through direct Python Code.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 1,
      "source": [
        "from taipy import Config\n",
        "import taipy as tp\n",
        "\n",
        "# Normal function used by Taipy\n",
        "def double(nb):\n",
        "    return nb * 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Two Data Nodes are being configured 'input' and 'output'. The 'input' Data Node has a _default_data_ put at 21. They will be stored as Pickle files automatically and they are unique to their scenario.\n",
        "\n",
        "The task links the two Data Nodes through the Python function _double_.\n",
        "\n",
        "The pipeline will contain this one task and the scenario will contain this one pipeline.\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "    Here is the code to configure a simple scenario.\n",
        "\n",
        "    ```python\n",
        "    # Configuration of Data Nodes\n",
        "    input_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
        "    output_data_node_cfg = Config.configure_data_node(\"output\")\n",
        "\n",
        "    # Configuration of tasks\n",
        "    task_cfg = Config.configure_task(\"double\",\n",
        "                                     double,\n",
        "                                     input_data_node_cfg,\n",
        "                                     output_data_node_cfg)\n",
        "\n",
        "    # Configuration of the pipeline and scenario\n",
        "    pipeline_cfg = Config.configure_pipeline(\"my_pipeline\", [task_cfg])\n",
        "    scenario_cfg = Config.configure_scenario(\"my_scenario\", [pipeline_cfg])\n",
        "    ```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 2,
      "source": [
        "# Run of the Core\n",
        "tp.Core().run()\n",
        "\n",
        "# Creation of the scenario and execution\n",
        "scenario = tp.create_scenario(scenario_cfg)\n",
        "tp.submit(scenario)\n",
        "\n",
        "print(\"Value at the end of task\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    [2022-12-22 16:20:02,740][Taipy][INFO] job JOB_double_699613f8-7ff4-471b-b36c-d59fb6688905 is completed.\n",
        "    Value at the end of task 42\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic functions\n",
        "\n",
        "Let's discuss about the basic functions that comes along with Taipy.\n",
        "\n",
        "-_write_: this is how data can be changed through Taipy. _write_ will change the _last_edit_date_ of the data node which will influence if a task can be skipped or not.\n",
        "\n",
        "-_tp.get_scenarios()_: this function returns a list of all the scenarios\n",
        "\n",
        "-_tp.get(ID)_: this function returns an entity based on the id of the entity\n",
        "\n",
        "-_tp.delete(ID)_: this function deletes the entity and nested elements based on the id of the entity\n",
        "\n",
        "## Utility of having scenarios\n",
        "\n",
        "Taipy lets the user create multiple instances of the same configuration. Datas can differ between instances and can be used to compare different scenarios.\n",
        "\n",
        "Datas can be naturally different depending on the input data nodes or the randomness of functions. Moreover, the user can change them with the _write_ function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 3,
      "source": [
        "scenario = tp.create_scenario(scenario_cfg, name=\"Scenario\")\n",
        "tp.submit(scenario)\n",
        "print(\"First submit\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    [2022-12-22 16:20:02,874][Taipy][INFO] job JOB_double_a5ecfa4d-1963-4776-8f68-0859d22970b9 is completed.\n",
        "    First submit 42\n",
        "    \n",
        "\n",
        "By using _write_, data of a Data Node can be changed. The syntax is `<Scenario>.<Pipeline>.<Data Node>.write(value)`. If there is just one pipeline, we can just write `<Scenario>.<Data Node>.write(value)`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 4,
      "source": [
        "print(\"Before write\", scenario.input.read())\n",
        "scenario.input.write(54)\n",
        "print(\"After write\",scenario.input.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Before write 21\n",
        "    After write 54\n",
        "    \n",
        "\n",
        "The submission of the scenario will update the output values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 5,
      "source": [
        "tp.submit(scenario)\n",
        "print(\"Second submit\",scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    [2022-12-22 16:20:03,011][Taipy][INFO] job JOB_double_7eee213f-062c-4d67-b0f8-4b54c04e45e7 is completed.\n",
        "    Second submit 108\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 6,
      "source": [
        "# Basic functions of Taipy Core \n",
        "# how to access all the scenarios\n",
        "print([s.input.read() for s in tp.get_scenarios()])\n",
        "\n",
        "# how to get a scenario from its id\n",
        "scenario = tp.get(scenario.id)\n",
        "\n",
        "# how to delete a scenario\n",
        "tp.delete(scenario.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    [21, 54]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Different types of Data Nodes:\n",
        "\n",
        "- *Pickle* (default): Taipy can store and read anykind of data that can be serializable.\n",
        "\n",
        "- *CSV*: Taipy can read and store any dataframe as a CSV.\n",
        "\n",
        "- *JSON*: Taipy can read and store any JSONable data as a JSON file.\n",
        "\n",
        "- *SQL*: Taipy can read and store a table or data base.\n",
        "\n",
        "- *Generic*: Taipy provides a generic Data Node that can read and store any data based on the reding and writing function created by the user.\n",
        "\n",
        "The execution graph used to explain the different concepts is quite simple.\n",
        "\n",
        "Three Data Nodes:\n",
        "- historical data: initial CSV DataFrame\n",
        "- month_data: DataFrame after the filtering on the month (pd.DataFrame as a Pickle file)\n",
        "- nb_of_values: number of values in this month (int as a Pickle file)\n",
        "\n",
        "Two tasks linking these Data Nodes:\n",
        "- filter: filters on the months of the dataframe\n",
        "- count_values: calculates the number of elements in this month\n",
        "\n",
        "One pipeline in a scenario gathering these two tasks\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://docs.taipy.io/en/latest/getting_started/step_03/config.png width=700>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 7,
      "source": [
        "import datetime as dt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 8,
      "source": [
        "def filter_current(df):\n",
        "    current_month = dt.datetime.now().month\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == current_month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "    ```python\n",
        "    # here is a CSV Data Node\n",
        "    historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                         default_path=\"time_series.csv\")\n",
        "    month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
        "    nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n",
        "    ```\n",
        "\n",
        "\n",
        "    ```python\n",
        "    task_filter_current_cfg = Config.configure_task(id=\"filter_current\",\n",
        "                                                     function=filter_current,\n",
        "                                                     input=historical_data_cfg,\n",
        "                                                     output=month_values_cfg)\n",
        "\n",
        "    task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                     function=count_values,\n",
        "                                                     input=month_values_cfg,\n",
        "                                                     output=nb_of_values_cfg)\n",
        "    ```\n",
        "\n",
        "\n",
        "    ```python\n",
        "    pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                             task_configs=[task_filter_current_cfg,\n",
        "                                                           task_count_values_cfg])\n",
        "\n",
        "    scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                             pipeline_configs=[pipeline_cfg])\n",
        "\n",
        "    #scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "    #                                                    task_configs=[task_filter_current_cfg,\n",
        "    #                                                                  task_count_values_cfg])\n",
        "    ```\n",
        "\n",
        "\n",
        "```Python\n",
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "scenario_1.submit()\n",
        "\n",
        "scenario_2 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "scenario_2.submit()\n",
        "```\n",
        "\n",
        "    [2022-12-22 16:20:03,424][Taipy][INFO] job JOB_filter_current_257edf8d-3ca3-46f5-aec6-c8a413c86c43 is completed.\n",
        "    [2022-12-22 16:20:03,510][Taipy][INFO] job JOB_count_values_90c9b3c7-91e7-49ef-9064-69963d60f52a is completed.\n",
        "    [2022-12-22 16:20:03,755][Taipy][INFO] job JOB_filter_current_4adc91ee-cd64-4ebf-819b-8643da0282fd is completed.\n",
        "    [2022-12-22 16:20:03,901][Taipy][INFO] job JOB_count_values_968c8c34-2ed4-4f89-995c-a4137af82beb is completed.\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    {'PIPELINE_my_pipeline_b751f808-87de-4de1-866f-c1b3dd7bba19': [<taipy.core.job.job.Job at 0x219403b6080>,\n",
        "      <taipy.core.job.job.Job at 0x219403b7c40>]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Cycles :\n",
        "\n",
        "So far, we have talked about how having different scenarios helps us to oversee our assumptions about the future. For example, in business, it is critical to weigh different options to come up with an optimal solution. However, this decision-making process isn\u00e2\u20ac\u2122t just a one-time task but rather a recurrent operation that happens over a time period. This is why we want to introduce Cycles.\n",
        "\n",
        "A cycle can be thought of as a place to store different and recurrent scenarios within a time frame. In Taipy Core, each Cycle will have a unique primary scenario representing the reference scenario for a time period.\n",
        "\n",
        "\n",
        "In the step's example, scenarios are attached to a MONTHLY cycle. Using Cycles is useful because some specific Taipy's functions exist to navigate through these Cycles. Taipy can get all the scenarios created in a month by providing the Cycle. You can also get every primary scenario ever made to see their progress over time quickly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 9,
      "source": [
        "from taipy.core.config import Frequency\n",
        "\n",
        "def filter_by_month(df, month):\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "        ```python\n",
        "        historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                             default_path=\"time_series.csv\")\n",
        "        month_cfg =  Config.configure_data_node(id=\"month\")\n",
        "        month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
        "        nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n",
        "\n",
        "\n",
        "        task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
        "                                                         function=filter_by_month,\n",
        "                                                         input=[historical_data_cfg, month_cfg],\n",
        "                                                         output=month_values_cfg)\n",
        "\n",
        "        task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                         function=count_values,\n",
        "                                                         input=month_values_cfg,\n",
        "                                                         output=nb_of_values_cfg)\n",
        "\n",
        "        pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                                 task_configs=[task_filter_by_month_cfg,\n",
        "                                                               task_count_values_cfg])\n",
        "\n",
        "        scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                                 pipeline_configs=[pipeline_cfg],\n",
        "                                                 frequency=Frequency.MONTHLY)\n",
        "\n",
        "\n",
        "        #scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "        #                                                    task_configs=[task_filter_by_month_cfg,\n",
        "        #                                                    task_count_values_cfg])\n",
        "        ```\n",
        "\n",
        "\n",
        "\n",
        "As you can see, a Cycle can be made very easily once you have the desired frequency. In this snippet of code, since we have specified frequency=Frequency.MONTHLY, the corresponding scenario will be automatically attached to the correct period (month) once it is created.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 10,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,5),\n",
        "                                name=\"Scenario 2022/10/5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Scenario 1 and 2 belongs to the same cycle but they don't share the same data node. Each one have a Data Node by itself.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 11,
      "source": [
        "scenario_1.month.write(10)\n",
        "scenario_2.month.write(10)\n",
        "\n",
        "\n",
        "print(\"Month Data Node of Scenario 1\", scenario_1.month.read())\n",
        "print(\"Month Data Node of Scenario 2\", scenario_2.month.read())\n",
        "\n",
        "scenario_1.submit()\n",
        "scenario_2.submit()\n",
        "\n",
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2022/9/1\")\n",
        "scenario_3.month.write(9)\n",
        "scenario_3.submit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Month Data Node of Scenario 1 10\n",
        "    Month Data Node of Scenario 2 10\n",
        "    [2022-12-22 16:20:04,746][Taipy][INFO] job JOB_filter_by_month_a4d3c4a7-5ec9-4cca-8a1b-578c910e255a is completed.\n",
        "    [2022-12-22 16:20:04,833][Taipy][INFO] job JOB_count_values_a81b2f60-e9f9-4848-aa58-272810a0b755 is completed.\n",
        "    [2022-12-22 16:20:05,026][Taipy][INFO] job JOB_filter_by_month_22a3298b-ac8d-4b55-b51f-5fab0971cc9e is completed.\n",
        "    [2022-12-22 16:20:05,084][Taipy][INFO] job JOB_count_values_a52b910a-4024-443e-8ea2-f3cdda6c1c9d is completed.\n",
        "    [2022-12-22 16:20:05,317][Taipy][INFO] job JOB_filter_by_month_8643e5cf-e863-434f-a1ba-18222d6faab8 is completed.\n",
        "    [2022-12-22 16:20:05,376][Taipy][INFO] job JOB_count_values_72ab71be-f923-4898-a8a8-95ec351c24d9 is completed.\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    {'PIPELINE_my_pipeline_8f1e1475-9294-41be-a9da-70539491524a': [<taipy.core.job.job.Job at 0x21940433580>,\n",
        "      <taipy.core.job.job.Job at 0x21940431750>]}\n",
        "\n",
        "Also, as you can see every scenario has been submitted and executed entirely. However, the result for these tasks are all the same. Caching will help to skip certain redundant task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Scoping \n",
        "\n",
        "Scoping determines how Data Nodes are shared between cycles, scenarios, and pipelines. Indeed, multiple scenarios can have their own Data Nodes or share the same one. For example, the initial/historical dataset is usually shared by all the scenarios/pipelines/cycles. It has a Global Scope and will be unique in the entire application.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 12,
      "source": [
        "from taipy.core.config import Scope\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 13,
      "source": [
        "def filter_by_month(df, month):\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- **Pipeline** scope: two pipelines can reference different Data Nodes even if their names are the same. For example, the _prediction_ Data Node of an ARIMA model (ARIMA pipeline) and the _prediction_ Data Node of a RandomForest model (RandomForest pipeline). \n",
        "\n",
        "- **Scenario** scope: pipelines share the same Data Node within a scenario. \n",
        "\n",
        "- **Cycle** scope: scenarios from the same cycle share the same Data Node\n",
        "\n",
        "- **Global** scope: unique Data Node for all the scenarios/pipelines/cycles\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "    ```python\n",
        "    historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                     default_path=\"time_series.csv\",\n",
        "                                                     scope=Scope.GLOBAL)\n",
        "    month_cfg =  Config.configure_data_node(id=\"month\", scope=Scope.CYCLE)\n",
        "\n",
        "    month_values_cfg = Config.configure_data_node(id=\"month_data\",\n",
        "                                                   scope=Scope.CYCLE)\n",
        "    nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n",
        "\n",
        "\n",
        "    task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
        "                                                     function=filter_by_month,\n",
        "                                                     input=[historical_data_cfg,month_cfg],\n",
        "                                                     output=month_values_cfg)\n",
        "\n",
        "    task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                     function=count_values,\n",
        "                                                     input=month_values_cfg,\n",
        "                                                     output=nb_of_values_cfg)\n",
        "\n",
        "    pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                             task_configs=[task_filter_by_month_cfg,\n",
        "                                                           task_count_values_cfg])\n",
        "\n",
        "    scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                             pipeline_configs=[pipeline_cfg],\n",
        "                                             frequency=Frequency.MONTHLY)\n",
        "\n",
        "\n",
        "    #scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "    #                                                    task_configs=[task_filter_by_month_cfg,\n",
        "    #                                                                  task_count_values_cfg])\n",
        "    ```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 14,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                               creation_date=dt.datetime(2022,10,5),\n",
        "                               name=\"Scenario 2022/10/5\")\n",
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2021/9/1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Scenario 1 and 2 belongs to the same cycle so I can define the month just once for scenario 1 and 2 because month has a Cycle scope.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=https://docs.taipy.io/en/latest/getting_started/step_05/sommething.png width=700>\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 15,
      "source": [
        "scenario_1.month.write(10)\n",
        "print(\"Scenario 1: month\", scenario_1.month.read())\n",
        "print(\"Scenario 2: month\", scenario_2.month.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 1: month 10\n",
        "    Scenario 2: month 10\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 16,
      "source": [
        "print(\"\\nScenario 1: submit\")\n",
        "scenario_1.submit()\n",
        "print(\"Value\", scenario_1.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \n",
        "    Scenario 1: submit\n",
        "    [2022-12-22 16:20:05,810][Taipy][INFO] job JOB_filter_by_month_d71cfd10-f674-40c8-b7a5-c66bea8773ef is completed.\n",
        "    [2022-12-22 16:20:05,902][Taipy][INFO] job JOB_count_values_cbe0b3b3-2531-440a-9413-48845c9cfdf1 is completed.\n",
        "    Value 849\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 17,
      "source": [
        "print(\"Scenario 2: submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 2: submit\n",
        "    [2022-12-22 16:20:06,356][Taipy][INFO] job JOB_filter_by_month_705fcb69-64fc-4f66-a5f3-90169e09f8bf is completed.\n",
        "    [2022-12-22 16:20:06,426][Taipy][INFO] job JOB_count_values_5a8eea88-4477-48ab-a401-8036bada2267 is completed.\n",
        "    Value 849\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 18,
      "source": [
        "print(\"\\nScenario 3: submit\")\n",
        "scenario_3.month.write(9)\n",
        "scenario_3.submit()\n",
        "print(\"Value\", scenario_3.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \n",
        "    Scenario 3: submit\n",
        "    [2022-12-22 16:20:07,404][Taipy][INFO] job JOB_filter_by_month_d0eefd6f-af96-46b8-b916-7cb94303ae4d is completed.\n",
        "    [2022-12-22 16:20:07,578][Taipy][INFO] job JOB_count_values_469f6ae3-7a8a-4b65-9175-899399013f60 is completed.\n",
        "    Value 1012\n",
        "    \n",
        "\n",
        "Each `nb_of_values` has their own value for each scenario, they have a Scenario scope.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Caching\n",
        "\n",
        "Caching is an important feature of Taipy. Tasks can be skipped depending if input data nodes of tasks have changed or not. If none of the input data nodes have been changed after a first submission, tasks will be skipped saving time and ressources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 19,
      "source": [
        "def filter_by_month(df, month):\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "    ```python\n",
        "    historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                     default_path=\"time_series.csv\",\n",
        "                                                     scope=Scope.GLOBAL)\n",
        "    month_cfg =  Config.configure_data_node(id=\"month\", scope=Scope.CYCLE)\n",
        "    month_values_cfg =  Config.configure_data_node(id=\"month_data\",\n",
        "                                                   scope=Scope.CYCLE,\n",
        "                                                   cacheable=True)\n",
        "\n",
        "    nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\",\n",
        "                                                  cacheable=True)\n",
        "\n",
        "\n",
        "    task_filter_by_month_cfg = Config.configure_task(id=\"filter_by_month\",\n",
        "                                                     function=filter_by_month,\n",
        "                                                     input=[historical_data_cfg, month_cfg],\n",
        "                                                     output=month_values_cfg)\n",
        "\n",
        "    task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                     function=count_values,\n",
        "                                                     input=month_values_cfg,\n",
        "                                                     output=nb_of_values_cfg)\n",
        "\n",
        "    pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                             task_configs=[task_filter_by_month_cfg,\n",
        "                                                           task_count_values_cfg])\n",
        "\n",
        "    scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                             pipeline_configs=[pipeline_cfg],\n",
        "                                             frequency=Frequency.MONTHLY)\n",
        "\n",
        "    #scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "    #                                                    task_configs=[task_filter_by_month_cfg,\n",
        "    #                                                    task_count_values_cfg])\n",
        "    ```\n",
        "\n",
        "The configuration is the same. 'cacheabable' are added to the output Data Nodes that we want to be cached.\n",
        "Creation of three different scenarios with different creation dates and names.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 20,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                               creation_date=dt.datetime(2022,10,5),\n",
        "                               name=\"Scenario 2022/10/5\")\n",
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2022/9/1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 21,
      "source": [
        "# scenario 1 and 2 belongs to the same cycle so \n",
        "# defining the month for scenario 1 defines the month for the scenarios in the cycle\n",
        "scenario_1.month.write(10)\n",
        "print(\"Scenario 1: month\", scenario_1.month.read())\n",
        "print(\"Scenario 2: month\", scenario_2.month.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 1: month 10\n",
        "    Scenario 2: month 10\n",
        "    \n",
        "\n",
        " No task has already been submitted so everything will be submitted\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 22,
      "source": [
        "print(\"Scenario 1: submit\")\n",
        "scenario_1.submit()\n",
        "print(\"Value\", scenario_1.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 1: submit\n",
        "    [2022-12-22 16:20:09,079][Taipy][INFO] job JOB_filter_by_month_0d7836eb-70eb-4fe6-b954-0e56967831b6 is completed.\n",
        "    [2022-12-22 16:20:09,177][Taipy][INFO] job JOB_count_values_91214241-ce81-42d8-9025-e83509652133 is completed.\n",
        "    Value 849\n",
        "    \n",
        "\n",
        "When the second scenario is being executed, the first task will be skipped. Indeed, the two scenarios shares the same data nodes for this task and no input data nodes have been changed. node\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 23,
      "source": [
        "# first task has already been executed by scenario 1 because scenario 2 shares the same data node for this task\n",
        "print(\"Scenario 2: first submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 2: first submit\n",
        "    [2022-12-22 16:20:09,317][Taipy][INFO] job JOB_filter_by_month_c1db1f0c-6e0a-4691-b0a3-331d473c4c42 is skipped.\n",
        "    [2022-12-22 16:20:09,371][Taipy][INFO] job JOB_count_values_271cefd0-8648-47fa-8948-ed49e93e3eee is completed.\n",
        "    Value 849\n",
        "    \n",
        "\n",
        "Resubmitting the same scenario without any change will just skip every task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 24,
      "source": [
        "# every task has already been executed so everything will be skipped\n",
        "print(\"Scenario 2: second submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 2: second submit\n",
        "    [2022-12-22 16:20:09,516][Taipy][INFO] job JOB_filter_by_month_da2762d1-6f24-40c1-9bd1-d6786fee7a8d is skipped.\n",
        "    [2022-12-22 16:20:09,546][Taipy][INFO] job JOB_count_values_9071dff4-37b2-4095-a7ed-34ef81daad27 is skipped.\n",
        "    Value 849\n",
        "    \n",
        "\n",
        "This scenario is not in the same cycle. We change the month to 9 and every task will be completed. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 25,
      "source": [
        "# scenario 3 has no connection to the other scenarios so everything will be executed\n",
        "print(\"Scenario 3: submit\")\n",
        "scenario_3.month.write(9)\n",
        "scenario_3.submit()\n",
        "print(\"Value\", scenario_3.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 3: submit\n",
        "    [2022-12-22 16:20:10,071][Taipy][INFO] job JOB_filter_by_month_c4d06eba-a149-4b79-9194-78972c7b7a18 is completed.\n",
        "    [2022-12-22 16:20:10,257][Taipy][INFO] job JOB_count_values_817df173-6bae-4742-a2c0-b8b8eba52872 is completed.\n",
        "    Value 1012\n",
        "    \n",
        "\n",
        "Here, we change the input data node of the pipeline so Taipy will re run the correct tasks to make sure that everything is up-to-date.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 26,
      "source": [
        "# changing an input data node will make the task be reexecuted\n",
        "print(\"Scenario 3: change in historical data\")\n",
        "scenario_3.historical_data.write(pd.read_csv('time_series_2.csv'))\n",
        "scenario_3.submit()\n",
        "print(\"Value\", scenario_3.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    Scenario 3: change in historical data\n",
        "    [2022-12-22 16:20:10,870][Taipy][INFO] job JOB_filter_by_month_92f32135-b410-41f0-b9f3-a852c2eb07cd is completed.\n",
        "    [2022-12-22 16:20:10,932][Taipy][INFO] job JOB_count_values_a6a75e13-4cd4-4f7e-bc4e-d14a86733440 is completed.\n",
        "    Value 1012\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Execution modes\n",
        "\n",
        "Taipy has different ways to execute the code. There is two different job execution modes:\n",
        "- standalone: asynchronous. Jobs can be runned in parallel depending on the graph of execution if max_nb_of_workers > 1\n",
        "- development mode: synchronous\n",
        "\n",
        "Options of submit:\n",
        "- wait: if wait is True, the submit is synchronous and will wait for the end of all the jobs (if timeout is not defined)\n",
        "- timeout: if wait is True, Taipy will wait for the end of the submit until a certain amount of time\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 27,
      "source": [
        "#  Taipy Core Data nodes - CSV, pickle\n",
        "from taipy.core.config import Config, Scope, Frequency\n",
        "import taipy as tp\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 28,
      "source": [
        "# Normal function used by Taipy\n",
        "def double(nb):\n",
        "    return nb * 2\n",
        "\n",
        "def add(nb):\n",
        "    print(\"Wait 10 seconds in add function\")\n",
        "    time.sleep(10)\n",
        "    return nb + 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "=== \"Python configuration\"\n",
        "\n",
        "    ```python\n",
        "\n",
        "    # Configuration of Data Nodes\n",
        "    input_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
        "    intermediate_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
        "    output_data_node_cfg = Config.configure_data_node(\"output\")\n",
        "\n",
        "    # Configuration of tasks\n",
        "    first_task_cfg = Config.configure_task(\"double\",\n",
        "                                        double,\n",
        "                                        input_data_node_cfg,\n",
        "                                        intermediate_data_node_cfg)\n",
        "\n",
        "    second_task_cfg = Config.configure_task(\"add\",\n",
        "                                        add,\n",
        "                                        intermediate_data_node_cfg,\n",
        "                                        output_data_node_cfg)\n",
        "\n",
        "    # Configuration of the pipeline and scenario\n",
        "    pipeline_cfg = Config.configure_pipeline(\"my_pipeline\", [first_task_cfg, second_task_cfg])\n",
        "    scenario_cfg = Config.configure_scenario(\"my_scenario\", [pipeline_cfg])\n",
        "\n",
        "    #scenario_cfg = Config.configure_scenario_from_tasks(id=\"my_scenario\",\n",
        "    #                                                    task_configs=[first_task_cfg, second_task_cfg])\n",
        "    ```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 29,
      "source": [
        "Config.configure_job_executions(mode=\"standalone\", max_nb_of_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    <taipy.core.config.job_config.JobConfig at 0x2193e63c3d0>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 30,
      "source": [
        "if __name__==\"__main__\":\n",
        "    tp.Core().run()\n",
        "    scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "    scenario_1.month.write(10)\n",
        "    scenario_1.submit()\n",
        "    scenario_1.submit()\n",
        "\n",
        "    time.sleep(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 31,
      "source": [
        "if __name__==\"__main__\":\n",
        "    tp.Core().run()\n",
        "    scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "    scenario_1.month.write(10)\n",
        "    scenario_1.submit(wait=True)\n",
        "    scenario_1.submit(wait=True, timeout=5)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}