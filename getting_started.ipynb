{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Taipy Core on Notebooks\n",
        "\n",
        "!!! important \"Supported Python versions\"\n",
        "\n",
        "    Taipy requires **Python 3.8** or newer.\n",
        "\n",
        "Welcome to the **Getting Started Core** guide for Taipy Core. This tour shows you how to use Taipy Core to orchestrate pipelines. Taipy Core implements a modern backend for any data-driven application based on your business case.\n",
        "\n",
        "\n",
        "# Taipy Core\n",
        "\n",
        "Taipy Core is one of the components of Taipy to facilitate pipeline orchestration. There are a lot of reasons for using Taipy Core:\n",
        "\n",
        "- Taipy Core efficiently manages the execution of your functions/pipelines.\n",
        "\n",
        "- Taipy Core manages data sources and monitors KPIs.\n",
        "\n",
        "- Taipy Core provides easy management of multiple pipelines and end-user scenarios, which comes in handy in the context of Machine Learning or Mathematical optimization.\n",
        "\n",
        "Each step of the **\"Getting Started Core\"** will focus on basic concepts of *Taipy Core*. Note that every step is dependent on \n",
        "the code of the previous one. After completing the last step, you will have the skills to develop your own Taipy \n",
        "application. \n",
        "\n",
        "## Before we begin\n",
        "\n",
        "Only Taipy has to be installed. **Taipy** package requires Python 3.8 or newer;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# !pip install taipy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Notebooks\n",
        "Using Notebooks, you **may want to restart the kernel** after a run of Taipy Core\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_01.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 1: Configuration and execution\n",
        "\n",
        "Before looking at some code examples, let\u00e2\u20ac\u2122s define some basic terms Taipy Core uses. Taipy Core revolves around four major concepts.\n",
        "\n",
        "## Four fundamental concepts in Taipy Core:\n",
        "- [**Data Nodes**](https://docs.taipy.io/en/latest/manuals/core/concepts/data-node/): are the translation of _variables_ in Taipy. Data Nodes don't contain the data but know how to retrieve it. They can refer to any data: any Python object (string, int, list, dict, model, data frame, etc.), a Pickle file, a CSV file, a SQL database, etc. They know how to read and write data. You can even write your own custom Data Node to access a particular data format.\n",
        "\n",
        "- [**Tasks**](https://docs.taipy.io/en/latest/manuals/core/concepts/task/): are the translation of _functions_ in Taipy.\n",
        "\n",
        "- [**Pipelines**](https://docs.taipy.io/en/latest/manuals/core/concepts/pipeline/): are a list of tasks executed with intelligent scheduling created automatically by Taipy. They usually represent a sequence of Tasks/functions ranging from data processing steps to simple baseline Algorithms all the way to more sophisticated pipelines: Machine-Learning, Mathematical models, Simulation, etc.\n",
        "\n",
        "- [**Scenarios**](https://docs.taipy.io/en/latest/manuals/core/concepts/scenario/): End-Users often require modifying various parameters to reflect different business situations. Taipy Scenarios provide the framework to \"run\"/\"execute\" pipelines under different conditions/variations (i.e., data/parameters modified by the end-user)\n",
        "\n",
        "\n",
        "## What is a configuration?\n",
        "\n",
        "A [**configuration**](https://docs.taipy.io/en/latest/manuals/core/config/) is a structure to define scenarios and pipelines. It represents our Direct Acyclic Graph(s); it models the data sources, parameters, and tasks. Once defined, a configuration acts like a superclass; it is used to generate different instances of scenarios.\n",
        "\n",
        "\n",
        "Let's create our first configuration. For this, we have two alternatives:\n",
        "\n",
        "- Using Taipy Studio\n",
        "\n",
        "- Or directly coding in Python.\n",
        "\n",
        "Once the scenario configuration is defined, we can create instances, aka *'entities'* of scenarios, that can be submitted for execution. Entities are made from all configuration objects: scenario config, pipeline config, tasks, and data node configs. We will refer to them as _scenario entities_, _pipeline entities_, _task entities_, and _Data Node entities_. Since this is very much like the mechanism of class and instances present in object programming, we will use the word entity and instance interchangeably. \n",
        "\n",
        "Let\u00e2\u20ac\u2122s consider the simplest possible pipeline: a single function taking as input an integer and generating an integer output (doubling the input number). See below:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 1,
      "source": [
        "from taipy import Config\n",
        "import taipy as tp\n",
        "\n",
        "# Normal function used by Taipy\n",
        "def double(nb):\n",
        "    return nb * 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_01/config_01.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "- Two Data Nodes are being configured ('input' and 'output'). The 'input' Data Node has a _default_data_ set at 21. They will be stored as Pickle files (default storage format) and unique to each scenario entity/instance (this is the concept of scope which is covered later\u00e2\u20ac\u2122). To clarify, the names given to the Data Nodes are arbitrary. The task links the two Data Nodes through the Python function double.\n",
        "\n",
        "- The pipeline contains this task, and the scenario includes this single pipeline.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Alternative 2:** Configuration using Python Code\n",
        "\n",
        "Here is the code to configure a simple scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 2,
      "source": [
        "# Configuration of Data Nodes\n",
        "input_data_node_cfg = Config.configure_data_node(\"input\", default_data=21)\n",
        "output_data_node_cfg = Config.configure_data_node(\"output\")\n",
        "\n",
        "# Configuration of tasks\n",
        "task_cfg = Config.configure_task(\"double\",\n",
        "                                 double,\n",
        "                                 input_data_node_cfg,\n",
        "                                 output_data_node_cfg)\n",
        "\n",
        "# Configuration of the pipeline and scenario\n",
        "pipeline_cfg = Config.configure_pipeline(\"my_pipeline\", [task_cfg])\n",
        "scenario_cfg = Config.configure_scenario(\"my_scenario\", [pipeline_cfg])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The code below presents how you can create scenarios and submit them.\n",
        "\n",
        "First of all, Taipy Core has to be launched(`tp.Core().run()`). It will create a service that acts as a job scheduler.\n",
        "\n",
        "Creating a scenario/pipeline (`tp.create_scenario(<Scenario Config>)` / `tp.create_pipeline(<Pipeline Config>)`) will create all its related entities (_tasks_, _Data Nodes_, etc). These entities are being created thanks to the previous configuration. Still, no scenario has been run yet. `tp.submit(<Scenario>)` is the line of code that will run all the scenario-related pipelines and tasks. Note that a pipeline or a task can also be submitted directly (`tp.submit(<Pipeline>)`, `tp.submit(<Task>)`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 3,
      "source": [
        "# Run of the Core\n",
        "tp.Core().run()\n",
        "\n",
        "# Creation of the scenario and execution\n",
        "scenario = tp.create_scenario(scenario_cfg)\n",
        "tp.submit(scenario)\n",
        "\n",
        "print(\"Value at the end of task\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "[2022-12-22 16:20:02,740][Taipy][INFO] job JOB_double_699613f8-7ff4-471b-b36c-d59fb6688905 is completed.\n",
        "Value at the end of task 42\n",
        "```\n",
        "\n",
        "'/.data' is the default storage folder for Taipy Core. It contains data, scenarios, pipelines, jobs, and tasks. These entities can be persisted between two runs depending on how the code is run.\n",
        "\n",
        "## Ways of executing the code: Versioning\n",
        "\n",
        "Taipy Core provides a [versioning system](https://docs.taipy.io/en/latest/manuals/core/versioning/) to keep track of the changes that a configuration will experience over time: new data sources, new parameters, new versions of your Machine Learning engine, etc. `python main.py -h` opens a helper to understand the versioning options. Here are the principal ways to run the code with versioning:\n",
        "\n",
        "- _Development_: is the default way of executing the code. When running a Taipy Core application in development mode, Taipy can\u00e2\u20ac\u2122t access all entities created from a previous Development run. Launching your Taipy code as `python main.py` executes it in Development mode.\n",
        "\n",
        "- _Experiment_: all Taipy Core entities from the previous run are kept, but each new run will ignore them. An identifier is attached to each run. \n",
        "`python main.py --experiment` will execute the code in Experiment mode. The user can then re-execute a previous run (by selecting a previously used identifier). This version number is as follows: `python main.py --experiment 1`.\n",
        "\n",
        "- _Production_: When running a Taipy Core application in production mode, Taipy can access all entities attached to the current or another production version. It corresponds to the case where the application is stable and running in a production environment. The user can decide the identifier to use. `python main.py --production` will execute the code in Experiment mode, or `python main.py --production 1` to run it with a specific version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_02.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 2: Basic functions\n",
        "\n",
        "Let's discuss some of the essential functions that come along with Taipy.\n",
        "\n",
        "- [`<Data Node>.write(<new value>)`](https://docs.taipy.io/en/latest/manuals/core/entities/data-node-mgt/#read-write-a-data-node): this instruction changes the data of a Data Node. It also changes the _last_edit_date_ of the Data Node, influencing whether a task can be skipped.\n",
        "\n",
        "- [`tp.get_scenarios()`](https://docs.taipy.io/en/latest/manuals/core/entities/scenario-cycle-mgt/#get-all-scenarios): this function returns the list of all the scenarios\n",
        "\n",
        "- [`tp.get(<Taipy object ID>)`](https://docs.taipy.io/en/latest/manuals/core/entities/data-node-mgt/#get-data-node): this function returns an entity based on the id of the entity\n",
        "\n",
        "- [`tp.delete(<Taipy object ID>)`](https://docs.taipy.io/en/latest/manuals/core/entities/scenario-cycle-mgt/#delete-a-scenario): this function deletes the entity and nested elements based on the id of the entity\n",
        "\n",
        "## Utility of having scenarios\n",
        "\n",
        "Taipy lets the user create multiple instances of the same configuration. Data can differ between different scenario instances. It is essential to detect/understand the difference in data between scenario instances: e.g., comparing the output/results of different instances... Such differences in behavior between different scenarios entities (from the same scenario configuration) can be due to the following:\n",
        "\n",
        "- Changing data from input data nodes, \n",
        "\n",
        "- Randomness in a task (random algorithm), \n",
        "\n",
        "- Different values from parameters set by the end-user, etc.\n",
        "\n",
        "The developer can directly change the data nodes entities with the _write_ function (see below).\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_02/config_02.svg\" width=700>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 4,
      "source": [
        "scenario = tp.create_scenario(scenario_cfg, name=\"Scenario\")\n",
        "tp.submit(scenario)\n",
        "print(\"Output of First submit:\", scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "[2022-12-22 16:20:02,874][Taipy][INFO] job JOB_double_a5ecfa4d-1963-4776-8f68-0859d22970b9 is completed.\n",
        "Output of First submit: 42\n",
        "```\n",
        "\n",
        "## _write_ function\n",
        "\n",
        "Data of a Data Node can be changed using _write_. The syntax is `<Scenario>.<Pipeline>.<Data Node>.write(value)`. If the scenario contains a single pipeline, we can write `<Scenario>.<Data Node>.write(value)`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 5,
      "source": [
        "print(\"Before write\", scenario.input.read())\n",
        "scenario.input.write(54)\n",
        "print(\"After write\",scenario.input.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "Before write 21\n",
        "After write 54\n",
        "```\n",
        "\n",
        "The submission of the scenario will update the output values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 6,
      "source": [
        "tp.submit(scenario)\n",
        "print(\"Second submit\",scenario.output.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "```\n",
        "[2022-12-22 16:20:03,011][Taipy][INFO] job JOB_double_7eee213f-062c-4d67-b0f8-4b54c04e45e7 is completed.\n",
        "Second submit 108\n",
        "```\n",
        "\n",
        "## Other useful functions\n",
        "\n",
        "- `tp.get_scenarios` accesses all the scenarios by returning a list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 7,
      "source": [
        "print([s.name for s in tp.get_scenarios()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "[\"Scenario\"]\n",
        "```\n",
        "\n",
        "- Get an entity from its id:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 8,
      "source": [
        "scenario = tp.get(scenario.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- Delete an entity through its id. For example, to delete a scenario:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 9,
      "source": [
        "tp.delete(scenario.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_04.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 3: Data Node types\n",
        "\n",
        "- *[Pickle](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#pickle)* (default): Taipy can read and write any data that can be serializable.\n",
        "\n",
        "- *[CSV](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#csv)*: Taipy can read and write any data frame as a CSV.\n",
        "\n",
        "- *[JSON](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#json)*: Taipy can read and write any JSONable data as a JSON file.\n",
        "\n",
        "- *[SQL](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#sql)*: Taipy can read and write from/to a SQL table or a SQL database.\n",
        "\n",
        "- *[Mongo](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#mongo-collection)*: Taipy can read and write from/to a Mongo Collection\n",
        "\n",
        "- *[Parquet](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#parquet)*: Taipy can read and write data frames from/to a Parquet format\n",
        "\n",
        "- *[Generic](https://docs.taipy.io/en/latest/manuals/core/config/data-node-config/#generic)*: Taipy provides a generic Data Node that can read and store any data based on a custom _reading_ and _writing_ function created by the user.\n",
        "\n",
        "This section will use the simple DAG/execution configuration described below. The configuration consists of the following:\n",
        "\n",
        "1. Three Data Nodes:\n",
        "2. \n",
        "-   _historical data_: This is a CSV-type Data Node. It reads from a CSV file into the initial data frame. You can find the dataset used in the Getting Started [here](https://github.com/Avaiga/taipy-getting-started-core/blob/develop/src/time_series.csv).\n",
        "\n",
        "-   _month_data_: This is a pickle Data Node. It stores in a pickle format the data frame generated by the task '_filter_' (obtained after some filtering of the initial data frame).\n",
        "\n",
        "-   _nb_of_values_: This is also a pickle Data Node. It stores an integer generated by the '_count_values_' task.  \n",
        "\n",
        "3. Two tasks linking these Data Nodes:\n",
        "\n",
        "-   _filter_: filters on the current month of the data frame\n",
        "\n",
        "-   _count_values_: calculates the number of elements in this month\n",
        "\n",
        "5. One single pipeline in this scenario configuration grouping these two tasks.\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_03/config_03.svg\" width=700>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 10,
      "source": [
        "def filter_current(df):\n",
        "    current_month = dt.datetime.now().month\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == current_month]\n",
        "    return df\n",
        "\n",
        "def count_values(df):\n",
        "    return len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 11,
      "source": [
        "# here is a CSV Data Node\n",
        "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                     default_path=\"time_series.csv\")\n",
        "month_values_cfg =  Config.configure_data_node(id=\"month_data\")\n",
        "nb_of_values_cfg = Config.configure_data_node(id=\"nb_of_values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 12,
      "source": [
        "task_filter_cfg = Config.configure_task(id=\"filter_current\",\n",
        "                                                 function=filter_current,\n",
        "                                                 input=historical_data_cfg,\n",
        "                                                 output=month_values_cfg)\n",
        "\n",
        "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                 function=count_values,\n",
        "                                                 input=month_values_cfg,\n",
        "                                                 output=nb_of_values_cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 13,
      "source": [
        "pipeline_cfg = Config.configure_pipeline(id=\"my_pipeline\",\n",
        "                                         task_configs=[task_filter_cfg,\n",
        "                                                       task_count_values_cfg])\n",
        "\n",
        "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                         pipeline_configs=[pipeline_cfg])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 14,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg, creation_date=dt.datetime(2022,10,7), name=\"Scenario 2022/10/7\")\n",
        "scenario_1.submit()\n",
        "\n",
        "print(\"Nb of values of scenario 1:\", scenario_1.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "[2022-12-22 16:20:03,424][Taipy][INFO] job JOB_filter_current_257edf8d-3ca3-46f5-aec6-c8a413c86c43 is completed.\n",
        "[2022-12-22 16:20:03,510][Taipy][INFO] job JOB_count_values_90c9b3c7-91e7-49ef-9064-69963d60f52a is completed.\n",
        "\n",
        "Nb of values of scenario 1: 896\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Cycles\n",
        "\n",
        "[Cycles](https://docs.taipy.io/en/latest/manuals/core/concepts/cycle/) have been introduced to reflect business situations our customers frequently encounter. \n",
        "\n",
        "For instance, a large Fast Food chain wants to generate sales forecasts for its stores every week. When creating a given scenario, it will need to be attached to a given week. And often, a single one will be published amongst all the scenarios generated for a given week. This kind of 'official' scenario will be referred to as the 'Primary' scenario in Taipy Core.\n",
        "\n",
        "Note that Cycles can be ignored entirely if the business problem has no time frequency. \n",
        "\n",
        "\n",
        "In this step, scenarios are attached to a MONTHLY cycle. Using Cycles, the developer will benefit from specific Taipy's functions to navigate through these Cycles. For instance, by providing the Cycle, Taipy can get all the scenarios created in a month. You can also easily get every primary scenario generated for the past X months to monitor KPIs over time.\n",
        "\n",
        "Let\u00e2\u20ac\u2122s slightly change the filter function by passing the month as an argument to get started. You must create a new Data Node representing the month (see the steps below).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 15,
      "source": [
        "def filter_by_month(df, month):\n",
        "    df['Date'] = pd.to_datetime(df['Date']) \n",
        "    df = df[df['Date'].dt.month == month]\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Then to introduce Cycles, you need to set the frequency (predefined attribute) of the scenario to Monthly (as described below).\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_04/config_04.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The configuration is the same as the last step except for the scenario and task configuration. A new parameter is added for the frequency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 16,
      "source": [
        "from taipy.config import Scope\n",
        "\n",
        "month_cfg =  Config.configure_data_node(id=\"month\")\n",
        "\n",
        "task_filter_cfg = Config.configure_task(id=\"filter_by_month\",\n",
        "                                             function=filter_by_month,\n",
        "                                             input=[historical_data_cfg, month_cfg],\n",
        "                                             output=month_values_cfg)\n",
        "\n",
        "...\n",
        "\n",
        "scenario_cfg = Config.configure_scenario(id=\"my_scenario\",\n",
        "                                         pipeline_configs=[pipeline_cfg],\n",
        "                                         frequency=Frequency.MONTHLY)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "As you can see, a Cycle is activated once you have set the desired frequency on the scenario. In this code snippet, since we have specified `frequency=Frequency.MONTHLY`, the corresponding scenario will be automatically attached to the correct period (month) once it is created. The _creation_date_ here is artificially given to the scenarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 17,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,5),\n",
        "                                name=\"Scenario 2022/10/5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Scenario 1 and Scenario 2 are two scenario entities/instances created from the same scenario configuration. They belong to the same Cycle but don't share the same Data Nodes. By default, each scenario instance has its own data node instances. They are not shared with any other scenario. The Scope concept can modify this behavior, which will be covered in the next step.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 18,
      "source": [
        "scenario_1.month.write(10)\n",
        "scenario_2.month.write(10)\n",
        "\n",
        "\n",
        "print(\"Month Data Node of Scenario 1\", scenario_1.month.read())\n",
        "print(\"Month Data Node of Scenario 2\", scenario_2.month.read())\n",
        "\n",
        "scenario_1.submit()\n",
        "scenario_2.submit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Results:\n",
        "```\n",
        "Month Data Node of Scenario 1 10\n",
        "Month Data Node of Scenario 2 10\n",
        "[2022-12-22 16:20:04,746][Taipy][INFO] job JOB_filter_by_month_a4d3c4a7-5ec9-4cca-8a1b-578c910e255a is completed.\n",
        "[2022-12-22 16:20:04,833][Taipy][INFO] job JOB_count_values_a81b2f60-e9f9-4848-aa58-272810a0b755 is completed.\n",
        "[2022-12-22 16:20:05,026][Taipy][INFO] job JOB_filter_by_month_22a3298b-ac8d-4b55-b51f-5fab0971cc9e is completed.\n",
        "[2022-12-22 16:20:05,084][Taipy][INFO] job JOB_count_values_a52b910a-4024-443e-8ea2-f3cdda6c1c9d is completed.\n",
        "[2022-12-22 16:20:05,317][Taipy][INFO] job JOB_filter_by_month_8643e5cf-e863-434f-a1ba-18222d6faab8 is completed.\n",
        "[2022-12-22 16:20:05,376][Taipy][INFO] job JOB_count_values_72ab71be-f923-4898-a8a8-95ec351c24d9 is completed.\n",
        "```\n",
        "\n",
        "## Primary scenarios\n",
        "\n",
        "In each Cycle, there is a primary scenario. A primary scenario is interesting because it represents the important scenario of the Cycle, the reference. By default, the first scenario created for a cycle will be primary.\n",
        "\n",
        "[`tp.set_primary(<Scenario>)`](https://docs.taipy.io/en/latest/manuals/core/entities/scenario-cycle-mgt/#promote-a-scenario-as-primary) allows changing the primary scenario in a Cycle.\n",
        "\n",
        "`<Scenario>.is_primary` identifies as a boolean whether the scenario is primary or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 19,
      "source": [
        "print(\"Scenario 1 before\", scenario_1.is_primary)\n",
        "print(\"Scenario 2 before\", scenario_2.is_primary)\n",
        "\n",
        "tp.set_primary(scenario_2)\n",
        "\n",
        "print(\"Scenario 1 after\", scenario_1.is_primary)\n",
        "print(\"Scenario 2 after\", scenario_2.is_primary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "Scenario 1 before True\n",
        "Scenario 2 before False\n",
        "Scenario 1 after False\n",
        "Scenario 2 after True\n",
        "```\n",
        "\n",
        "Scenario 3 is the only scenario in another Cycle due to its creation date and is the default primary scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 20,
      "source": [
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2022/9/1\")\n",
        "scenario_3.month.write(9)\n",
        "scenario_3.submit()\n",
        "\n",
        "print(\"Is scenario 3 primary?\", scenario_3.is_primary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "[2022-12-22 16:20:05,317][Taipy][INFO] job JOB_filter_by_month_8643e5cf-e863-434f-a1ba-18222d6faab8 is completed.\n",
        "[2022-12-22 16:20:05,376][Taipy][INFO] job JOB_count_values_72ab71be-f923-4898-a8a8-95ec351c24d9 is completed.\n",
        "\n",
        "Is scenario 3 primary? True\n",
        "```\n",
        "\n",
        "Also, as you can see, every scenario has been submitted and executed entirely. However, the results for these tasks are all the same. Skipping Tasks (defined in subsequent steps) will help optimize your executions by skipping the execution of redundant tasks.\n",
        "\n",
        "## Useful functions on cycles\n",
        "\n",
        "- `tp.get_primary_scenarios()`: returns a list of all primary scenarios\n",
        "\n",
        "- `tp.get_scenarios(cycle=<Cycle>)`: returns all the scenarios in the Cycle\n",
        "\n",
        "- `tp.get_cycles()`: returns the list of Cycles\n",
        "\n",
        "- `tp.get_primary(<Cycle>)`: returns the primary scenario of the Cycle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_05.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 5: Scopes\n",
        "\n",
        "[Scopes](https://docs.taipy.io/en/latest/manuals/core/concepts/scope/) determine how Data Nodes are shared between cycles, scenarios, and pipelines. The developer may decide to:\n",
        "\n",
        "- Keep Data Nodes local to each pipeline.\n",
        "\n",
        "- Extend the scope by sharing data nodes between a given scenario's pipelines.\n",
        "\n",
        "- Extend the scope by sharing data nodes across all scenarios of a given cycle.\n",
        "\n",
        "- Finally, extend the scope globally (across all scenarios of all cycles). For example, the initial/historical dataset is usually shared by all the scenarios/pipelines/cycles. It has a Global Scope and will be unique in the entire application.\n",
        "\n",
        "To summarize, the different possible scopes are:\n",
        "\n",
        "- _Pipeline scope_: two pipelines can reference different Data Nodes even if their names are the same. For example, we can have a _prediction_ Data Node of an ARIMA model (ARIMA pipeline) and a _prediction_ Data Node of a RandomForest model (RandomForest pipeline). A scenario can contain multiple pipelines.\n",
        "\n",
        "- _Scenario scope (default)_: pipelines share the same Data Node within a scenario. \n",
        "\n",
        "- _Cycle scope_: scenarios from the same Cycle share the same Data Node.\n",
        "\n",
        "- _Global scope_: Data Nodes are shared across all the scenarios/pipelines/cycles.\n",
        "\n",
        "It is worth noting that the default scope for Data nodes is the Scenario scope.\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_05/config_05.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Modifying the scope of a Data Node is as simple as changing its Scope parameter inside the configuration.\n",
        "\n",
        "The configuration is taken in the previous step so you can copy the previous code directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 21,
      "source": [
        "from taipy.config import Scope, Frequency\n",
        "\n",
        "historical_data_cfg = Config.configure_csv_data_node(id=\"historical_data\",\n",
        "                                                 default_path=\"time_series.csv\",\n",
        "                                                 scope=Scope.GLOBAL)\n",
        "month_cfg =  Config.configure_data_node(id=\"month\", scope=Scope.CYCLE)\n",
        "\n",
        "month_values_cfg = Config.configure_data_node(id=\"month_data\",\n",
        "                                               scope=Scope.CYCLE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Cycles are created based on the _creation_date_ of scenarios. In the example below, we force the creation_date to a given date (in real life, the actual creation date of the scenario gets used automatically).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 22,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                               creation_date=dt.datetime(2022,10,5),\n",
        "                               name=\"Scenario 2022/10/5\")\n",
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2021/9/1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Scenario 1 and 2 belong to the same Cycle: since _month_ now has a **Cycle** scope, we can define _month_ just once for both scenarios: 1 and 2.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 23,
      "source": [
        "scenario_1.month.write(10)\n",
        "scenario_3.month.write(9)\n",
        "print(\"Scenario 1: month\", scenario_1.month.read())\n",
        "print(\"Scenario 2: month\", scenario_2.month.read())\n",
        "print(\"Scenario 3: month\", scenario_2.month.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "```\n",
        "Scenario 1: month 10\n",
        "Scenario 2: month 10\n",
        "Scenario 3: month 9\n",
        "```\n",
        "\n",
        "Defining the _month_ of scenario 1 will also determine the _month_ of scenario 2 since they share the same Data Node. \n",
        "\n",
        "This is not the case for _nb_of_values_ that are of Scenario scope; each _nb_of_values_ has its own value in each scenario.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_06.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 6: Skipping tasks\n",
        "\n",
        "Skipping tasks is an essential feature of Taipy. Running twice a function with the same input parameters will create the same output for a given pipeline or scenario. Executing this sort of function is a waste of time and resources.\n",
        "\n",
        "Taipy Core provides for each task the _skippable_ attribute. If this attribute is set to True, Taipy Core\u00e2\u20ac\u2122s scheduler will automatically detect if changes have occurred on any of the input Data Nodes of a task. If no changes have occurred, it will automatically skip the execution of that task. By default, skippable is set to False. \n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_06/config_06.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 24,
      "source": [
        "task_filter_cfg = Config.configure_task(id=\"filter_by_month\",\n",
        "                                             function=filter_by_month,\n",
        "                                             input=[historical_data_cfg, month_cfg],\n",
        "                                             output=month_values_cfg,\n",
        "                                             skippable=True)\n",
        "\n",
        "task_count_values_cfg = Config.configure_task(id=\"count_values\",\n",
        "                                                 function=count_values,\n",
        "                                                 input=month_values_cfg,\n",
        "                                                 output=nb_of_values_cfg,\n",
        "                                                 skippable=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The configuration is almost the same. `skippable=True` are added to the tasks we want to be skipped.\n",
        "\n",
        "Here we create three different scenarios with different creation dates and names. Scenario 1 and scenario 2 belong to the same cycle.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 25,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2022,10,7),\n",
        "                                name=\"Scenario 2022/10/7\")\n",
        "scenario_2 = tp.create_scenario(scenario_cfg,\n",
        "                               creation_date=dt.datetime(2022,10,5),\n",
        "                               name=\"Scenario 2022/10/5\")\n",
        "scenario_3 = tp.create_scenario(scenario_cfg,\n",
        "                                creation_date=dt.datetime(2021,9,1),\n",
        "                                name=\"Scenario 2022/9/1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 26,
      "source": [
        "# scenario 1 and 2 belong to the same cycle, so \n",
        "# defining the month for scenario 1 defines the month for the scenarios in the cycle\n",
        "scenario_1.month.write(10)\n",
        "print(\"Scenario 1: month\", scenario_1.month.read())\n",
        "print(\"Scenario 2: month\", scenario_2.month.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "Scenario 1: month 10\n",
        "Scenario 2: month 10\n",
        "```\n",
        "\n",
        "Every task has yet to be submitted, so when submitting scenario 1, all tasks will be executed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 27,
      "source": [
        "print(\"Scenario 1: submit\")\n",
        "scenario_1.submit()\n",
        "print(\"Value\", scenario_1.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "Scenario 1: submit\n",
        "[2022-12-22 16:20:09,079][Taipy][INFO] job JOB_filter_by_month_0d7836eb-70eb-4fe6-b954-0e56967831b6 is completed.\n",
        "[2022-12-22 16:20:09,177][Taipy][INFO] job JOB_count_values_91214241-ce81-42d8-9025-e83509652133 is completed.\n",
        "Value 849\n",
        "```\n",
        "\n",
        "When submitting scenario 2, the scheduler will skip the first task of this second scenario. Indeed, the two scenarios share the same input Data Nodes for this task, and no changes have occurred on these Data Nodes (since the last task run when we submitted scenario 1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 28,
      "source": [
        "# the first task has already been executed by scenario 1\n",
        "print(\"Scenario 2: first submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "Scenario 2: first submit\n",
        "[2022-12-22 16:20:09,317][Taipy][INFO] job JOB_filter_by_month_c1db1f0c-6e0a-4691-b0a3-331d473c4c42 is skipped.\n",
        "[2022-12-22 16:20:09,371][Taipy][INFO] job JOB_count_values_271cefd0-8648-47fa-8948-ed49e93e3eee is completed.\n",
        "Value 849\n",
        "```\n",
        "\n",
        "Resubmitting the same scenario without any change will skip every task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 29,
      "source": [
        "# every task has already been executed so that the scheduler will skip everything\n",
        "print(\"Scenario 2: second submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "Scenario 2: second submit\n",
        "[2022-12-22 16:20:09,516][Taipy][INFO] job JOB_filter_by_month_da2762d1-6f24-40c1-9bd1-d6786fee7a8d is skipped.\n",
        "[2022-12-22 16:20:09,546][Taipy][INFO] job JOB_count_values_9071dff4-37b2-4095-a7ed-34ef81daad27 is skipped.\n",
        "Value 849\n",
        "```\n",
        "\n",
        "This scenario is not in the same cycle. We change the month to 9, and the scheduler will complete every task. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 30,
      "source": [
        "# scenario 3 has no connection to the other scenarios, so everything will be executed\n",
        "print(\"Scenario 3: submit\")\n",
        "scenario_3.month.write(9)\n",
        "scenario_3.submit()\n",
        "print(\"Value\", scenario_3.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "```\n",
        "Scenario 3: submit\n",
        "[2022-12-22 16:20:10,071][Taipy][INFO] job JOB_filter_by_month_c4d06eba-a149-4b79-9194-78972c7b7a18 is completed.\n",
        "[2022-12-22 16:20:10,257][Taipy][INFO] job JOB_count_values_817df173-6bae-4742-a2c0-b8b8eba52872 is completed.\n",
        "Value 1012\n",
        "```  \n",
        "\n",
        "Here, we change the input Data Node of the pipeline so Taipy will re-run the correct tasks to ensure that everything is up-to-date.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 31,
      "source": [
        "# changing an input data node will make the task be executed\n",
        "print(\"Scenario 3: change in historical data\")\n",
        "scenario_3.historical_data.write(pd.read_csv('time_series_2.csv'))\n",
        "scenario_3.submit()\n",
        "print(\"Value\", scenario_3.nb_of_values.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Results:\n",
        "\n",
        "```\n",
        "Scenario 3: change in historical data\n",
        "[2022-12-22 16:20:10,870][Taipy][INFO] job JOB_filter_by_month_92f32135-b410-41f0-b9f3-a852c2eb07cd is completed.\n",
        "[2022-12-22 16:20:10,932][Taipy][INFO] job JOB_count_values_a6a75e13-4cd4-4f7e-bc4e-d14a86733440 is completed.\n",
        "Value 1012\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_07.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 7: Execution modes\n",
        "\n",
        "Taipy has [different ways](https://docs.taipy.io/en/latest/manuals/core/config/job-config/) to execute the code. Changing the execution mode can be useful for running multiple tasks in parallel.\n",
        "- _standalone_ mode: asynchronous. Jobs can be run in parallel depending on the graph of execution if _max_nb_of_workers_ > 1.\n",
        "- _development_ mode: synchronous.\n",
        "\n",
        "In this step, we define a new configuration and functions to showcase the two execution modes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 32,
      "source": [
        "# Normal function used by Taipy\n",
        "def double(nb):\n",
        "    return nb * 2\n",
        "\n",
        "def add(nb):\n",
        "    print(\"Wait 10 seconds in add function\")\n",
        "    time.sleep(10)\n",
        "    return nb + 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_07/config_07.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "This line of code will change the execution mode (the default execution mode is _development_). Changing it to _standalone_ will make Taipy Core asynchronous. Here a maximum of two tasks will be able to run concurrently.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 33,
      "source": [
        "Config.configure_job_executions(mode=\"standalone\", max_nb_of_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 34,
      "source": [
        "if __name__==\"__main__\":\n",
        "    tp.Core().run()\n",
        "    scenario_1 = tp.create_scenario(scenario_cfg)\n",
        "    scenario_1.submit()\n",
        "    scenario_1.submit()\n",
        "\n",
        "    time.sleep(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Jobs from the two submissions are being executed simultaneously. If `max_nb_of_workers` was greater, we could run multiple scenarios at the same time and multiple tasks of a scenario at the same time.\n",
        "\n",
        "Some options for the [_submit_](https://docs.taipy.io/en/latest/manuals/reference/taipy.core.Scenario/#taipy.core.scenario.scenario.Scenario.submit) function exist:\n",
        "- _wait_: if _wait_ is True, the submit is synchronous and will wait for the end of all the jobs (if _timeout_ is not defined).\n",
        "- _timeout_: if _wait_ is True, Taipy will wait for the end of the submission up to a certain amount of time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 35,
      "source": [
        "if __name__==\"__main__\":\n",
        "    tp.Core().run()\n",
        "    scenario_1 = tp.create_scenario(scenario_cfg)\n",
        "    scenario_1.submit(wait=True)\n",
        "    scenario_1.submit(wait=True, timeout=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> You can download the code of this step [here](https://docs.taipy.io/en/latest/getting_started/src/step_08.py) or all the steps [here](https://github.com/Avaiga/taipy-getting-started-core/tree/develop/src).\n",
        "\n",
        "# Step 8: Scenario comparison\n",
        "\n",
        "This step reuses the configuration provided in the previous step except for the [scenario configuration](https://docs.taipy.io/en/latest/manuals/core/entities/scenario-cycle-mgt/#compare-scenarios).\n",
        "\n",
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/Avaiga/taipy-getting-started-core/develop/step_08/config_08.svg\" width=700>\n",
        "</div>\n",
        "\n",
        "Taipy provides a mechanism to compare scenarios by providing a function directly into the scenario's configuration.\n",
        "\n",
        "## Step 1: The first step consists in declaring on which data nodes to apply the comparison functions:\n",
        "\n",
        "Taipy can compare Data Nodes. In this example, we want a comparison applied to the '_output_' Data Node. It is indicated in the comparators parameter of the `configure_scenario()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 36,
      "source": [
        "scenario_cfg = Config.configure_scenario(id=\"multiply_scenario\",\n",
        "                                        name=\"my_scenario\",\n",
        "                                        pipeline_configs=[pipeline_cfg],\n",
        "                                        comparators={output_data_node_cfg.id: compare_function},\n",
        "                                        frequency=Frequency.MONTHLY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Implement the comparison function (`compare_function()`) used above.\n",
        "\n",
        "_data_node_results_ is the list of the Output Data Nodes from all scenarios passed in the comparator. We iterate through it to compare scenarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 37,
      "source": [
        "def compare_function(*data_node_results):\n",
        "    compare_result= {}\n",
        "    current_res_i = 0\n",
        "    for current_res in data_node_results:\n",
        "        compare_result[current_res_i]={}\n",
        "        next_res_i = 0\n",
        "        for next_res in data_node_results:\n",
        "            print(f\"comparing result {current_res_i} with result {next_res_i}\")\n",
        "            compare_result[current_res_i][next_res_i] = next_res - current_res\n",
        "            next_res_i += 1\n",
        "        current_res_i += 1\n",
        "    return compare_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Now, the `compare_scenarios()` can be used within Taipy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 38,
      "source": [
        "tp.Core().run()\n",
        "\n",
        "scenario_1 = tp.create_scenario(scenario_cfg)\n",
        "scenario_2 = tp.create_scenario(scenario_cfg)\n",
        "\n",
        "\n",
        "print(\"\\nScenario 1: submit\")\n",
        "scenario_1.submit()\n",
        "print(\"Value\", scenario_1.output.read())\n",
        "\n",
        "print(\"\\nScenario 2: first submit\")\n",
        "scenario_2.submit()\n",
        "print(\"Value\", scenario_2.output.read())\n",
        "\n",
        "\n",
        "print(tp.compare_scenarios(scenario_1, scenario_2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Taipy Rest\n",
        "\n",
        "Taipy Rest allows the user to navigate through the entities of the application but also create and submit scenarios. Taipy Rest commands are referenced [here](https://docs.taipy.io/en/latest/manuals/reference_rest/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 39,
      "source": [
        "tp.Rest().run()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}